[
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "MixedModels.jl is part of the JuliaStats ecosystem and so shares a number of interface and design elements with GLM.jl. MixedModels.jl can also be viewed as the next step in the research programme behind the R package lme4 (and further back, nlme). The focus of development is on linear mixed effects models with unconstrained covariance matrices, with a secondary focus on generalized linear mixed effects models. We’ll come back to this focus later, when we discuss limitations of the software. For now, let us start off with a simple mixed model.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#optimization-results",
    "href": "01-intro.html#optimization-results",
    "title": "Introduction",
    "section": "Optimization results",
    "text": "Optimization results\nFor more technically oriented users and debugging problematic models, the fitted model also includes information about its fit:\n\nfm1.optsum\n\n\n\n\n\n\n\n\nInitialization\n\n\n\nInitial parameter vector\n[1.0, 1.0, 1.0]\n\n\nInitial objective value\n241905.85361894369\n\n\nOptimizer settings\n\n\n\nOptimizer (from NLopt)\nLN_BOBYQA\n\n\nLower bounds\n[0.0, 0.0, 0.0]\n\n\nftol_rel\n1.0e-12\n\n\nftol_abs\n1.0e-8\n\n\nxtol_rel\n0.0\n\n\nxtol_abs\n[1.0e-10, 1.0e-10, 1.0e-10]\n\n\ninitial_step\n[0.75, 0.75, 0.75]\n\n\nmaxfeval\n-1\n\n\nmaxtime\n-1.0\n\n\nResult\n\n\n\nFunction evaluations\n97\n\n\nFinal parameter vector\n[0.2775, 0.4341, 0.0669]\n\n\nFinal objective value\n237553.9858\n\n\nReturn code\nFTOL_REACHED",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#best-linear-unbiased-predictions",
    "href": "01-intro.html#best-linear-unbiased-predictions",
    "title": "Introduction",
    "section": "Best linear unbiased predictions",
    "text": "Best linear unbiased predictions\nWe can also examine the best linear unbiased predictions (BLUPS, i.e. conditional modes) of the fitted model:\n\n# gives a compact mathematical representation\nranef(fm1)\n\n3-element Vector{Matrix{Float64}}:\n [0.16774123178334052 -0.04482694183068773 … 0.13824421252672484 0.26507732678861823]\n [0.38719882629204333 -0.45435181953200804 … 0.5663054833894617 -0.2322561040271726]\n [0.01925158595457121 -0.0314237380877306 … -0.0394324632568055 0.010868838311276535]\n\n\n\n# gives a NamedTuple of tables for each grouping variable\nre = raneftables(fm1)\n\n(s = @NamedTuple{s::String, (Intercept)::Float64}[(s = \"S0001\", var\"(Intercept)\" = 0.16774123178334052), (s = \"S0002\", var\"(Intercept)\" = -0.04482694183068773), (s = \"S0003\", var\"(Intercept)\" = 0.31575885609970306), (s = \"S0004\", var\"(Intercept)\" = 0.24940695145339822), (s = \"S0005\", var\"(Intercept)\" = 0.05086330189212764), (s = \"S0006\", var\"(Intercept)\" = 0.10070570655847189), (s = \"S0007\", var\"(Intercept)\" = 0.49346335551085657), (s = \"S0008\", var\"(Intercept)\" = 0.21230052405523037), (s = \"S0009\", var\"(Intercept)\" = 0.43329760696045716), (s = \"S0010\", var\"(Intercept)\" = 0.3474382457376265)  …  (s = \"S2963\", var\"(Intercept)\" = -0.07493268898885441), (s = \"S2964\", var\"(Intercept)\" = -0.07639875902063552), (s = \"S2965\", var\"(Intercept)\" = -0.01269753658773821), (s = \"S2966\", var\"(Intercept)\" = -0.05968365555624512), (s = \"S2967\", var\"(Intercept)\" = -0.47762073203601624), (s = \"S2968\", var\"(Intercept)\" = -0.03808065216440611), (s = \"S2969\", var\"(Intercept)\" = 0.013164293735230988), (s = \"S2970\", var\"(Intercept)\" = 0.15284750426572696), (s = \"S2971\", var\"(Intercept)\" = 0.13824421252672484), (s = \"S2972\", var\"(Intercept)\" = 0.26507732678861823)], d = @NamedTuple{d::String, (Intercept)::Float64}[(d = \"I0001\", var\"(Intercept)\" = 0.38719882629204333), (d = \"I0006\", var\"(Intercept)\" = -0.45435181953200804), (d = \"I0007\", var\"(Intercept)\" = 0.6941269521055441), (d = \"I0008\", var\"(Intercept)\" = -0.6556986845555067), (d = \"I0012\", var\"(Intercept)\" = 0.2232265515513102), (d = \"I0013\", var\"(Intercept)\" = 0.35851586978902583), (d = \"I0014\", var\"(Intercept)\" = 0.3672805427901967), (d = \"I0015\", var\"(Intercept)\" = -0.37841197668279464), (d = \"I0017\", var\"(Intercept)\" = 0.4490422906985483), (d = \"I0018\", var\"(Intercept)\" = -0.21303124506473872)  …  (d = \"I2143\", var\"(Intercept)\" = 0.46453745653954004), (d = \"I2145\", var\"(Intercept)\" = -0.5103188066752637), (d = \"I2146\", var\"(Intercept)\" = 0.24093975571844684), (d = \"I2147\", var\"(Intercept)\" = -0.60947032761476), (d = \"I2149\", var\"(Intercept)\" = -0.2569371800839588), (d = \"I2152\", var\"(Intercept)\" = -0.1486343267392193), (d = \"I2153\", var\"(Intercept)\" = -0.4582448890911759), (d = \"I2156\", var\"(Intercept)\" = -0.598164389730049), (d = \"I2157\", var\"(Intercept)\" = 0.5663054833894617), (d = \"I2160\", var\"(Intercept)\" = -0.2322561040271726)], dept = @NamedTuple{dept::String, (Intercept)::Float64}[(dept = \"D01\", var\"(Intercept)\" = 0.01925158595457121), (dept = \"D02\", var\"(Intercept)\" = -0.0314237380877306), (dept = \"D03\", var\"(Intercept)\" = 0.026989756564498747), (dept = \"D04\", var\"(Intercept)\" = 0.08634883593136969), (dept = \"D05\", var\"(Intercept)\" = 0.0425384283501927), (dept = \"D06\", var\"(Intercept)\" = -0.0612386105577639), (dept = \"D07\", var\"(Intercept)\" = 0.037994105160680386), (dept = \"D08\", var\"(Intercept)\" = 0.10706977660601054), (dept = \"D09\", var\"(Intercept)\" = -0.03130386231393186), (dept = \"D10\", var\"(Intercept)\" = -0.13074749481062195), (dept = \"D11\", var\"(Intercept)\" = -0.05345274044982538), (dept = \"D12\", var\"(Intercept)\" = 0.016537582598079168), (dept = \"D14\", var\"(Intercept)\" = -0.0394324632568055), (dept = \"D15\", var\"(Intercept)\" = 0.010868838311276535)])\n\n\n\nre[:dept]\n\nTable with 2 columns and 14 rows:\n      dept  (Intercept)\n    ┌──────────────────\n 1  │ D01   0.0192516\n 2  │ D02   -0.0314237\n 3  │ D03   0.0269898\n 4  │ D04   0.0863488\n 5  │ D05   0.0425384\n 6  │ D06   -0.0612386\n 7  │ D07   0.0379941\n 8  │ D08   0.10707\n 9  │ D09   -0.0313039\n 10 │ D10   -0.130747\n 11 │ D11   -0.0534527\n 12 │ D12   0.0165376\n 13 │ D14   -0.0394325\n 14 │ D15   0.0108688\n\n\nSimilarly, condVar and condVartables provide similar results for the conditional variances, which can be used to construct prediction intervals. Note that this quantity is slightly more challenging to compute, so the next code chunk can be quite slow for large and/or complex models.\n\ncv = condVartables(fm1)\n\n(s = (s = [\"S0001\", \"S0002\", \"S0003\", \"S0004\", \"S0005\", \"S0006\", \"S0007\", \"S0008\", \"S0009\", \"S0010\"  …  \"S2963\", \"S2964\", \"S2965\", \"S2966\", \"S2967\", \"S2968\", \"S2969\", \"S2970\", \"S2971\", \"S2972\"], σ = [(0.2858669689270982,), (0.30401631752599356,), (0.22821157590283608,), (0.25780032906103995,), (0.2860219499541289,), (0.25793951955717076,), (0.26490082020646233,), (0.2783368253958202,), (0.2522473463464451,), (0.22880831550861952,)  …  (0.20261426533573362,), (0.15345460348688958,), (0.1890606491627694,), (0.2364492114093623,), (0.16864266061743807,), (0.13248230048424514,), (0.21568690433796606,), (0.15989932548370614,), (0.19703921571219082,), (0.17611120732728797,)], ρ = [(), (), (), (), (), (), (), (), (), ()  …  (), (), (), (), (), (), (), (), (), ()]), d = (d = [\"I0001\", \"I0006\", \"I0007\", \"I0008\", \"I0012\", \"I0013\", \"I0014\", \"I0015\", \"I0017\", \"I0018\"  …  \"I2143\", \"I2145\", \"I2146\", \"I2147\", \"I2149\", \"I2152\", \"I2153\", \"I2156\", \"I2157\", \"I2160\"], σ = [(0.2944722990101209,), (0.1998490792256777,), (0.1976067001224343,), (0.15270441118675238,), (0.2050062557300713,), (0.18323918475417014,), (0.20826372508991525,), (0.1379768365880709,), (0.09916344786890752,), (0.25898396366164883,)  …  (0.27099005487450534,), (0.278560313176016,), (0.2642024787031552,), (0.11352578408559302,), (0.2148321233886452,), (0.28061080140124645,), (0.21640468799848833,), (0.26558809165790237,), (0.18875484054677152,), (0.12464395110737535,)], ρ = [(), (), (), (), (), (), (), (), (), ()  …  (), (), (), (), (), (), (), (), (), ()]), dept = (dept = [\"D01\", \"D02\", \"D03\", \"D04\", \"D05\", \"D06\", \"D07\", \"D08\", \"D09\", \"D10\", \"D11\", \"D12\", \"D14\", \"D15\"], σ = [(0.05342275258013416,), (0.05695221129282561,), (0.05309362315152055,), (0.04189159945771541,), (0.05536549244050585,), (0.04470905986933437,), (0.053575423476545404,), (0.05037317159100928,), (0.05202142805811866,), (0.047679287077604354,), (0.0522411612413694,), (0.04219045746979842,), (0.052986775032521645,), (0.048625616226665495,)], ρ = [(), (), (), (), (), (), (), (), (), (), (), (), (), ()]))\n\n\n\n# this output still isn't pretty, but we're working on it!\ncv[:dept]\n\n(dept = [\"D01\", \"D02\", \"D03\", \"D04\", \"D05\", \"D06\", \"D07\", \"D08\", \"D09\", \"D10\", \"D11\", \"D12\", \"D14\", \"D15\"], σ = [(0.05342275258013416,), (0.05695221129282561,), (0.05309362315152055,), (0.04189159945771541,), (0.05536549244050585,), (0.04470905986933437,), (0.053575423476545404,), (0.05037317159100928,), (0.05202142805811866,), (0.047679287077604354,), (0.0522411612413694,), (0.04219045746979842,), (0.052986775032521645,), (0.048625616226665495,)], ρ = [(), (), (), (), (), (), (), (), (), (), (), (), (), ()])\n\n\nAt this point, it becomes convenient to place everything into a dataframe so that we can easily manipulate the relevant quantities.\n\nusing DataFrames\ndept = DataFrame(cv[:dept])\n\n14×3 DataFrame\n\n\n\nRow\ndept\nσ\nρ\n\n\n\nString\nTuple…\nTuple{}\n\n\n\n\n1\nD01\n(0.0534228,)\n()\n\n\n2\nD02\n(0.0569522,)\n()\n\n\n3\nD03\n(0.0530936,)\n()\n\n\n4\nD04\n(0.0418916,)\n()\n\n\n5\nD05\n(0.0553655,)\n()\n\n\n6\nD06\n(0.0447091,)\n()\n\n\n7\nD07\n(0.0535754,)\n()\n\n\n8\nD08\n(0.0503732,)\n()\n\n\n9\nD09\n(0.0520214,)\n()\n\n\n10\nD10\n(0.0476793,)\n()\n\n\n11\nD11\n(0.0522412,)\n()\n\n\n12\nD12\n(0.0421905,)\n()\n\n\n13\nD14\n(0.0529868,)\n()\n\n\n14\nD15\n(0.0486256,)\n()\n\n\n\n\n\n\nLet’s construct prediction intervals:\n\nselect!(dept, :dept, :σ =&gt; ByRow(first) =&gt; :condvar)\nleftjoin!(dept, DataFrame(re[:dept]); on=:dept)\n\n14×3 DataFrame\n\n\n\nRow\ndept\ncondvar\n(Intercept)\n\n\n\nString\nFloat64\nFloat64?\n\n\n\n\n1\nD01\n0.0534228\n0.0192516\n\n\n2\nD02\n0.0569522\n-0.0314237\n\n\n3\nD03\n0.0530936\n0.0269898\n\n\n4\nD04\n0.0418916\n0.0863488\n\n\n5\nD05\n0.0553655\n0.0425384\n\n\n6\nD06\n0.0447091\n-0.0612386\n\n\n7\nD07\n0.0535754\n0.0379941\n\n\n8\nD08\n0.0503732\n0.10707\n\n\n9\nD09\n0.0520214\n-0.0313039\n\n\n10\nD10\n0.0476793\n-0.130747\n\n\n11\nD11\n0.0522412\n-0.0534527\n\n\n12\nD12\n0.0421905\n0.0165376\n\n\n13\nD14\n0.0529868\n-0.0394325\n\n\n14\nD15\n0.0486256\n0.0108688\n\n\n\n\n\n\n\nselect!(dept, \"dept\", \"(Intercept)\" =&gt; \"blup\", \"condvar\")\ntransform!(dept,\n           [:blup, :condvar] =&gt; ByRow((x,y) -&gt; x - 1.96 * y) =&gt; :lower,\n           [:blup, :condvar] =&gt; ByRow((x,y) -&gt; x + 1.96 * y) =&gt; :upper)\n\n14×5 DataFrame\n\n\n\nRow\ndept\nblup\ncondvar\nlower\nupper\n\n\n\nString\nFloat64?\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nD01\n0.0192516\n0.0534228\n-0.085457\n0.12396\n\n\n2\nD02\n-0.0314237\n0.0569522\n-0.14305\n0.0802026\n\n\n3\nD03\n0.0269898\n0.0530936\n-0.0770737\n0.131053\n\n\n4\nD04\n0.0863488\n0.0418916\n0.0042413\n0.168456\n\n\n5\nD05\n0.0425384\n0.0553655\n-0.0659779\n0.151055\n\n\n6\nD06\n-0.0612386\n0.0447091\n-0.148868\n0.0263911\n\n\n7\nD07\n0.0379941\n0.0535754\n-0.0670137\n0.143002\n\n\n8\nD08\n0.10707\n0.0503732\n0.00833836\n0.205801\n\n\n9\nD09\n-0.0313039\n0.0520214\n-0.133266\n0.0706581\n\n\n10\nD10\n-0.130747\n0.0476793\n-0.224199\n-0.0372961\n\n\n11\nD11\n-0.0534527\n0.0522412\n-0.155845\n0.0489399\n\n\n12\nD12\n0.0165376\n0.0421905\n-0.0661557\n0.0992309\n\n\n13\nD14\n-0.0394325\n0.0529868\n-0.143287\n0.0644216\n\n\n14\nD15\n0.0108688\n0.0486256\n-0.0844374\n0.106175",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#measures-of-model-fit",
    "href": "01-intro.html#measures-of-model-fit",
    "title": "Introduction",
    "section": "Measures of model fit",
    "text": "Measures of model fit\nMixedModels.jl provides methods for the standard functions aic, aicc, bic, deviance, fitted, logliklihood, nobs, residuals.\nThe deviance is computed as -2 loglikelihood and is thus missing an additive constant for the saturated model. However, defining that constant is challenging for mixed models (what is the saturated model? do you saturate via the fixed or the random effects?) and that constant cancels out in the relevant computations.\nMixedModels.jl intentionally does not provide methods for r2 and adjr2. These quantities are notoriously difficult to define in a completely satisfactory way for mixed models and we, the developers, felt uncomfortable giving our implicit endorsement by defining them as part of the core package. That said, there is an implementation of a naive definition of the coefficient of determination in MixedModelsExtras.jl because it is a commonly requested measure and I felt that it was better to have a well-tested implementation than have users handroll their own buggy implementation of an already problematic measure.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#memory-allocation-vs.-fitting",
    "href": "01-intro.html#memory-allocation-vs.-fitting",
    "title": "Introduction",
    "section": "Memory allocation vs. fitting",
    "text": "Memory allocation vs. fitting\n\nusing Econ2024\nratings = Econ2024.dataset(\"ratings\")\n@time fm_ratings = LinearMixedModel(@formula(rating ~ 1 + (1|userId) + (1|movieId)), ratings)\n\n\n@time fit!(fm_ratings)",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#to-try-on-your-own-after-the-course",
    "href": "01-intro.html#to-try-on-your-own-after-the-course",
    "title": "Introduction",
    "section": "To try on your own after the course",
    "text": "To try on your own after the course\n\nusing Econ2024\nratings = DataFrame(Econ2024.dataset(\"ratings_genre\"))\ndescribe(ratings)\n\n\nusing StatsBase\nmcount = countmap(ratings.movieId)\nucount = countmap(ratings.userId)\nmexclude = Set(k for (k, v) in pairs(mcount) if v &lt; 50)\nuexclude = Set(k for (k, v) in pairs(ucount) if v &lt; 50)\nratings = subset(ratings,\n                 :movieId =&gt; ByRow(!in(mexclude)),\n                 :userId =&gt; ByRow(!in(uexclude)))\n\n\n# This takes about an hour on my home computer when using the full dataset\nform1 = @formula(rating ~ 0 + Action + Adventure + Animation +\n                             Children + Comedy + Crime +\n                             Documentary + Drama +\n                             Fantasy + Film_Noir +\n                             Horror + IMAX +\n                             Musical + Mystery + Romance +\n                             Sci_Fi + Thriller + War + Western +\n                             (1 | movieId) +\n                             (1 | userId))\nfit(MixedModel, form1, ratings)",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#very-few-options-for-covariance-structure",
    "href": "01-intro.html#very-few-options-for-covariance-structure",
    "title": "Introduction",
    "section": "Very few options for covariance structure",
    "text": "Very few options for covariance structure\nNonetheless, there is no free lunch and the tradeoff that we make is that it is much more difficult to formulate constraints on the covariance structure (whether on the random effects or on the response/residuals) in our formulation. MixedModels.jl currently supports precisely two covariance structures explicitly:\n\nunconstrained\nzero correlation (diagonal covariance structure)\n\nIt is also possible to express some models with compound symmetry by clever manipulation of the formula syntax (i.e. (1+c|g) for categorical c with compound symmetry is the same as (1|g) + (1|g&c)).\nMixedModels.jl does support constraining the residual variance to known scalar value, which is useful in meta-analysis.\nMetida.jl may provide an alternative if this functionality is required (not an endorsement).",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-sandwichrobust-variance-covariance-estimators",
    "href": "01-intro.html#no-support-for-sandwichrobust-variance-covariance-estimators",
    "title": "Introduction",
    "section": "No support for sandwich/robust variance-covariance estimators",
    "text": "No support for sandwich/robust variance-covariance estimators\nThis may change in the foreseeable future!\nIf this would be a valuable feature, then please file an issue. Issues are prioritized by the developers’ own needs and potential impact for users, so showing a large need for a feature will tend to increase its priority.\nFixedEffectsModels.jl may be a viable alternative (not an endorsement). It provides “fast estimation of linear models with IV and high dimensional categorical variables” and provides similar functionality to Stata’s reghdfe and R’s lfe and fixest.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-generalized-linear-mixed-models-with-a-dispersion-parameter",
    "href": "01-intro.html#no-support-for-generalized-linear-mixed-models-with-a-dispersion-parameter",
    "title": "Introduction",
    "section": "No support for generalized linear mixed models with a dispersion parameter",
    "text": "No support for generalized linear mixed models with a dispersion parameter\nWhile MixedModels.jl does nominally support any GLM family and link function support by GLM.jl, the results for model families with a dispersion parameter (normal with non-identity link, gamma, inverse Gaussian) are known to be incorrect. The package issues a warning if you attempt to fit such models.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-polytomous-responses",
    "href": "01-intro.html#no-support-for-polytomous-responses",
    "title": "Introduction",
    "section": "No support for polytomous responses",
    "text": "No support for polytomous responses\nMultinomial and ordered responses are not supported. I am unaware of a Julia package offering support for this.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-regularization-of-the-fixed-effects",
    "href": "01-intro.html#no-support-for-regularization-of-the-fixed-effects",
    "title": "Introduction",
    "section": "No support for regularization of the fixed effects",
    "text": "No support for regularization of the fixed effects\nHighDimMixedModels.jl may provide an alternative if this functionality is required (not an endorsement).",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-generalized-additive-mixed-models",
    "href": "01-intro.html#no-support-for-generalized-additive-mixed-models",
    "title": "Introduction",
    "section": "No support for generalized additive mixed models",
    "text": "No support for generalized additive mixed models\nGeneralized additive models can be expressed a mixed model, so supporting this would require “only” adding a translation layer.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-nonlinear-mixed-effects-models",
    "href": "01-intro.html#no-support-for-nonlinear-mixed-effects-models",
    "title": "Introduction",
    "section": "No support for nonlinear mixed effects models",
    "text": "No support for nonlinear mixed effects models\nPumas.jl (commercial) provides this (not an endorsement).",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "04-bootstrap.html",
    "href": "04-bootstrap.html",
    "title": "The Parametric Bootstrap",
    "section": "",
    "text": "Code\nprogress = false\nusing MixedModels\nusing Random\nFor the examples here, we’ll be once again using a model of the insteval dataset.\ninsteval = MixedModels.dataset(\"insteval\")\nie1 = fit(MixedModel,\n          @formula(y ~ 1 + studage + lectage + service + (1|s) + (1|d) + (1|dept)),\n          insteval; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2908\n0.0324\n101.45\n&lt;1e-99\n0.3264\n0.5106\n0.0787\n\n\nstudage: 4\n0.0519\n0.0232\n2.24\n0.0249\n\n\n\n\n\nstudage: 6\n0.0721\n0.0240\n3.01\n0.0026\n\n\n\n\n\nstudage: 8\n0.1363\n0.0264\n5.17\n&lt;1e-06\n\n\n\n\n\nlectage: 2\n-0.0808\n0.0154\n-5.25\n&lt;1e-06\n\n\n\n\n\nlectage: 3\n-0.1102\n0.0167\n-6.59\n&lt;1e-10\n\n\n\n\n\nlectage: 4\n-0.1892\n0.0196\n-9.65\n&lt;1e-21\n\n\n\n\n\nlectage: 5\n-0.1644\n0.0214\n-7.68\n&lt;1e-13\n\n\n\n\n\nlectage: 6\n-0.2460\n0.0205\n-12.01\n&lt;1e-32\n\n\n\n\n\nservice: Y\n-0.0727\n0.0135\n-5.40\n&lt;1e-07\n\n\n\n\n\nResidual\n1.1762\nOne of the advantages of MixedModels.jl compared to its predecessors is its speed, which means that techniques that require fitting many different models are more viable. One such technique is the parametric bootstrap, which is implemented in the function parametricbootstrap:\n@time pb1 = parametricbootstrap(MersenneTwister(42), 100, ie1; progress)\n\n145.711846 seconds (4.35 M allocations: 309.726 MiB, 0.07% gc time, 0.92% compilation time)\n\n\nMixedModelBootstrap with 100 samples\n      parameter  min         q25         median      mean        q75         ⋯\n    ┌─────────────────────────────────────────────────────────────────────────\n 1  │ β01        3.21783     3.26358     3.28986     3.29053     3.31213     ⋯\n 2  │ β02        -0.0139569  0.038696    0.0548509   0.0543033   0.0691479   ⋯\n 3  │ β03        0.0195404   0.0601318   0.0744778   0.0737247   0.0880094   ⋯\n 4  │ β04        0.0660657   0.123001    0.141956    0.143059    0.161691    ⋯\n 5  │ β05        -0.125172   -0.0900465  -0.0821355  -0.0829556  -0.0736902  ⋯\n 6  │ β06        -0.158731   -0.126321   -0.114572   -0.114729   -0.10407    ⋯\n 7  │ β07        -0.248297   -0.203881   -0.189177   -0.192144   -0.177192   ⋯\n 8  │ β08        -0.229774   -0.180099   -0.168365   -0.169053   -0.156476   ⋯\n 9  │ β09        -0.300539   -0.26488    -0.249537   -0.247632   -0.229222   ⋯\n 10 │ β10        -0.105656   -0.0818337  -0.0744016  -0.075008   -0.0670841  ⋯\n 11 │ σ          1.16957     1.17411     1.17636     1.17617     1.17837     ⋯\n 12 │ σ1         0.303494    0.322677    0.326415    0.326131    0.329607    ⋯\n 13 │ σ2         0.474794    0.500079    0.508222    0.508323    0.516091    ⋯\n 14 │ σ3         0.0         0.0541107   0.0704625   0.0702876   0.0876531   ⋯\n 15 │ θ1         0.257713    0.274375    0.277284    0.277288    0.2808      ⋯\n 16 │ θ2         0.404015    0.425369    0.432303    0.432192    0.438206    ⋯\n 17 │ θ3         0.0         0.045864    0.0597909   0.0597646   0.0743971   ⋯\nThe bootstrap object has several properties defined, perhaps the most relevant are:\n# row table of fixed effect coefficient estimates, errors and p values\npb1.coefpvalues\n\n1000-element Vector{@NamedTuple{iter::Int64, coefname::Symbol, β::Float64, se::Float64, z::Float64, p::Float64}}:\n (iter = 1, coefname = Symbol(\"(Intercept)\"), β = 3.2844928279434065, se = 0.032524210677454375, z = 100.98608880984162, p = 0.0)\n (iter = 1, coefname = Symbol(\"studage: 4\"), β = 0.06545758686582491, se = 0.023497284000323155, z = 2.78575119000667, p = 0.005340384547276788)\n (iter = 1, coefname = Symbol(\"studage: 6\"), β = 0.07436675005559862, se = 0.024299662954631682, z = 3.060402532925824, p = 0.0022103969202858778)\n (iter = 1, coefname = Symbol(\"studage: 8\"), β = 0.1344127262525718, se = 0.026741312887550595, z = 5.026407148287308, p = 4.997542824491115e-7)\n (iter = 1, coefname = Symbol(\"lectage: 2\"), β = -0.08689967179369408, se = 0.015507345987220238, z = -5.6037746152893595, p = 2.09733396977708e-8)\n (iter = 1, coefname = Symbol(\"lectage: 3\"), β = -0.11271177326879837, se = 0.016859623249765785, z = -6.685307945440843, p = 2.304395511113411e-11)\n (iter = 1, coefname = Symbol(\"lectage: 4\"), β = -0.19020613648594675, se = 0.01976629678254787, z = -9.622750208520811, p = 6.409411635232184e-22)\n (iter = 1, coefname = Symbol(\"lectage: 5\"), β = -0.16073781065271658, se = 0.021585081491058315, z = -7.446708538918545, p = 9.569771650128114e-14)\n (iter = 1, coefname = Symbol(\"lectage: 6\"), β = -0.2433509853336542, se = 0.020669173607966728, z = -11.77361949487216, p = 5.338388678449715e-32)\n (iter = 1, coefname = Symbol(\"service: Y\"), β = -0.0560241884982609, se = 0.013588893568175118, z = -4.122792500889719, p = 3.743068523497779e-5)\n ⋮\n (iter = 100, coefname = Symbol(\"studage: 4\"), β = 0.025227349131417828, se = 0.023200807563855428, z = 1.0873478891622528, p = 0.27688309181244464)\n (iter = 100, coefname = Symbol(\"studage: 6\"), β = 0.07088408313765594, se = 0.02400554782671742, z = 2.952820891625901, p = 0.003148846053869982)\n (iter = 100, coefname = Symbol(\"studage: 8\"), β = 0.10704597045770158, se = 0.02643330877571195, z = 4.049662165489474, p = 5.129162474702447e-5)\n (iter = 100, coefname = Symbol(\"lectage: 2\"), β = -0.0731927575822571, se = 0.015423996688310335, z = -4.745382086196182, p = 2.0811311858175712e-6)\n (iter = 100, coefname = Symbol(\"lectage: 3\"), β = -0.08389108088590261, se = 0.016760437632691503, z = -5.005303723231648, p = 5.577401856280357e-7)\n (iter = 100, coefname = Symbol(\"lectage: 4\"), β = -0.18179640493121893, se = 0.019656009990827204, z = -9.248896648712387, p = 2.2682189479956574e-20)\n (iter = 100, coefname = Symbol(\"lectage: 5\"), β = -0.14755537474768485, se = 0.02145735710981732, z = -6.876679825595775, p = 6.1263588182793464e-12)\n (iter = 100, coefname = Symbol(\"lectage: 6\"), β = -0.22400745235549124, se = 0.020548647689622977, z = -10.901323324970651, p = 1.1359305452386851e-27)\n (iter = 100, coefname = Symbol(\"service: Y\"), β = -0.07461312463098355, se = 0.01352818587611706, z = -5.515382869088685, p = 3.4802146900712763e-8)\n# row table of all parameter estimates\npb1.allpars\n\n(iter = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  100, 100, 100, 100, 100, 100, 100, 100, 100, 100], type = [\"β\", \"β\", \"β\", \"β\", \"β\", \"β\", \"β\", \"β\", \"β\", \"β\"  …  \"β\", \"β\", \"β\", \"β\", \"β\", \"β\", \"σ\", \"σ\", \"σ\", \"σ\"], group = Union{Missing, String}[missing, missing, missing, missing, missing, missing, missing, missing, missing, missing  …  missing, missing, missing, missing, missing, missing, \"s\", \"d\", \"dept\", \"residual\"], names = Union{Missing, String}[\"(Intercept)\", \"studage: 4\", \"studage: 6\", \"studage: 8\", \"lectage: 2\", \"lectage: 3\", \"lectage: 4\", \"lectage: 5\", \"lectage: 6\", \"service: Y\"  …  \"lectage: 2\", \"lectage: 3\", \"lectage: 4\", \"lectage: 5\", \"lectage: 6\", \"service: Y\", \"(Intercept)\", \"(Intercept)\", \"(Intercept)\", missing], value = [3.2844928279434065, 0.06545758686582491, 0.07436675005559862, 0.1344127262525718, -0.08689967179369408, -0.11271177326879837, -0.19020613648594675, -0.16073781065271658, -0.2433509853336542, -0.0560241884982609  …  -0.0731927575822571, -0.08389108088590261, -0.18179640493121893, -0.14755537474768485, -0.22400745235549124, -0.07461312463098355, 0.32664795073240843, 0.5286560253303741, 0.09096234925764528, 1.1778772795686734])\n# row table of fixed effect estimates\npb1.β\n\n1000-element Vector{@NamedTuple{iter::Int64, coefname::Symbol, β::Float64}}:\n (iter = 1, coefname = Symbol(\"(Intercept)\"), β = 3.2844928279434065)\n (iter = 1, coefname = Symbol(\"studage: 4\"), β = 0.06545758686582491)\n (iter = 1, coefname = Symbol(\"studage: 6\"), β = 0.07436675005559862)\n (iter = 1, coefname = Symbol(\"studage: 8\"), β = 0.1344127262525718)\n (iter = 1, coefname = Symbol(\"lectage: 2\"), β = -0.08689967179369408)\n (iter = 1, coefname = Symbol(\"lectage: 3\"), β = -0.11271177326879837)\n (iter = 1, coefname = Symbol(\"lectage: 4\"), β = -0.19020613648594675)\n (iter = 1, coefname = Symbol(\"lectage: 5\"), β = -0.16073781065271658)\n (iter = 1, coefname = Symbol(\"lectage: 6\"), β = -0.2433509853336542)\n (iter = 1, coefname = Symbol(\"service: Y\"), β = -0.0560241884982609)\n ⋮\n (iter = 100, coefname = Symbol(\"studage: 4\"), β = 0.025227349131417828)\n (iter = 100, coefname = Symbol(\"studage: 6\"), β = 0.07088408313765594)\n (iter = 100, coefname = Symbol(\"studage: 8\"), β = 0.10704597045770158)\n (iter = 100, coefname = Symbol(\"lectage: 2\"), β = -0.0731927575822571)\n (iter = 100, coefname = Symbol(\"lectage: 3\"), β = -0.08389108088590261)\n (iter = 100, coefname = Symbol(\"lectage: 4\"), β = -0.18179640493121893)\n (iter = 100, coefname = Symbol(\"lectage: 5\"), β = -0.14755537474768485)\n (iter = 100, coefname = Symbol(\"lectage: 6\"), β = -0.22400745235549124)\n (iter = 100, coefname = Symbol(\"service: Y\"), β = -0.07461312463098355)\n# summary table in wide format\npb1.tbl\n\nTable with 18 columns and 100 rows:\n      obj        β01      β02          β03        β04        β05         ⋯\n    ┌────────────────────────────────────────────────────────────��────────\n 1  │ 2.38696e5  3.28449  0.0654576    0.0743668  0.134413   -0.0868997  ⋯\n 2  │ 2.37312e5  3.32203  0.0517903    0.0670178  0.140742   -0.0950906  ⋯\n 3  │ 2.37357e5  3.23378  0.116201     0.12476    0.207755   -0.0790354  ⋯\n 4  │ 2.36992e5  3.37017  0.0338393    0.0450009  0.0898785  -0.0679428  ⋯\n 5  │ 2.37374e5  3.29213  0.0747803    0.0736114  0.123649   -0.0853712  ⋯\n 6  │ 2.38354e5  3.23252  0.0557169    0.0965588  0.168224   -0.110282   ⋯\n 7  ��� 2.38595e5  3.32446  0.059913     0.0739455  0.144132   -0.100117   ⋯\n 8  │ 237394.0   3.33964  0.000101602  0.0394911  0.111735   -0.0740082  ⋯\n 9  │ 2.37038e5  3.23416  0.0288773    0.0792363  0.143171   -0.0754491  ⋯\n 10 │ 2.37538e5  3.32298  0.0418344    0.0479324  0.117366   -0.0843251  ⋯\n 11 │ 2.37919e5  3.34143  0.00910533   0.0340325  0.109248   -0.087165   ⋯\n 12 │ 2.37707e5  3.24528  0.0830967    0.110315   0.193995   -0.0996083  ⋯\n 13 │ 2.37413e5  3.28979  0.053302     0.0813591  0.134691   -0.0804611  ⋯\n 14 │ 2.37776e5  3.2454   0.0078669    0.0846662  0.11677    -0.0655534  ⋯\n 15 │ 2.37429e5  3.2731   0.0656087    0.0609474  0.12065    -0.0701581  ⋯\n 16 │ 2.37344e5  3.26359  0.0708762    0.0925205  0.148036   -0.0778408  ⋯\n 17 │ 237108.0   3.28631  0.0531506    0.0802238  0.136806   -0.0839233  ⋯\n ⋮  │     ⋮         ⋮          ⋮           ⋮          ⋮          ⋮       ⋱",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#general-plotting",
    "href": "04-bootstrap.html#general-plotting",
    "title": "The Parametric Bootstrap",
    "section": "General plotting",
    "text": "General plotting\nWe can create a custom display of the bootstrap densities for the fixed effects and variance components. We’ll build this plot piecewise using AlgebraOfGraphics.\nWe start by grabbing all the parameter estimates and placing them in a dataframe for easier manipulation.\n\nusing AlgebraOfGraphics\nusing AlgebraOfGraphics: density # override Makie.density\nusing DataFrames\ndf =  DataFrame(pb1a.allpars)\n\n7000×5 DataFrame6975 rows omitted\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nβ\nmissing\n(Intercept)\n3.28408\n\n\n2\n1\nβ\nmissing\nstudage: 4\n0.0638134\n\n\n3\n1\nβ\nmissing\nstudage: 6\n0.0697497\n\n\n4\n1\nβ\nmissing\nstudage: 8\n0.130544\n\n\n5\n1\nβ\nmissing\nlectage: 2\n-0.0869565\n\n\n6\n1\nβ\nmissing\nlectage: 3\n-0.110721\n\n\n7\n1\nβ\nmissing\nlectage: 4\n-0.187548\n\n\n8\n1\nβ\nmissing\nlectage: 5\n-0.159629\n\n\n9\n1\nβ\nmissing\nlectage: 6\n-0.241548\n\n\n10\n1\nβ\nmissing\nservice: Y\n-0.0578331\n\n\n11\n1\nσ\ns\n(Intercept)\n0.350074\n\n\n12\n1\nσ\nd\n(Intercept)\n1.01893\n\n\n13\n1\nσ\ndept\n(Intercept)\n1.24209\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n6989\n500\nβ\nmissing\nstudage: 6\n0.0732301\n\n\n6990\n500\nβ\nmissing\nstudage: 8\n0.128215\n\n\n6991\n500\nβ\nmissing\nlectage: 2\n-0.0675102\n\n\n6992\n500\nβ\nmissing\nlectage: 3\n-0.10197\n\n\n6993\n500\nβ\nmissing\nlectage: 4\n-0.175881\n\n\n6994\n500\nβ\nmissing\nlectage: 5\n-0.158475\n\n\n6995\n500\nβ\nmissing\nlectage: 6\n-0.255234\n\n\n6996\n500\nβ\nmissing\nservice: Y\n-0.0724982\n\n\n6997\n500\nσ\ns\n(Intercept)\n0.378387\n\n\n6998\n500\nσ\nd\n(Intercept)\n0.447546\n\n\n6999\n500\nσ\ndept\n(Intercept)\n1.06067\n\n\n7000\n500\nσ\nresidual\nmissing\n1.17374\n\n\n\n\n\n\nWe then split the parameters up into the fixed effects, random effects and the residual standard deviation.\n\nfe = subset(df, :group =&gt; ByRow(ismissing))\nre = subset(df, :group =&gt; ByRow(g -&gt; !ismissing(g) && g != \"residual\"))\nresid = subset(df, :group =&gt; ByRow(g -&gt; !ismissing(g) && g == \"residual\"))\n\n500×5 DataFrame475 rows omitted\n\n\n\nRow\niter\ntype\ngroup\nnames\nvalue\n\n\n\nInt64\nString\nString?\nString?\nFloat64\n\n\n\n\n1\n1\nσ\nresidual\nmissing\n1.17659\n\n\n2\n2\nσ\nresidual\nmissing\n1.16269\n\n\n3\n3\nσ\nresidual\nmissing\n1.16128\n\n\n4\n4\nσ\nresidual\nmissing\n1.16787\n\n\n5\n5\nσ\nresidual\nmissing\n1.16338\n\n\n6\n6\nσ\nresidual\nmissing\n1.16883\n\n\n7\n7\nσ\nresidual\nmissing\n1.17022\n\n\n8\n8\nσ\nresidual\nmissing\n1.16208\n\n\n9\n9\nσ\nresidual\nmissing\n1.17053\n\n\n10\n10\nσ\nresidual\nmissing\n1.16385\n\n\n11\n11\nσ\nresidual\nmissing\n1.17993\n\n\n12\n12\nσ\nresidual\nmissing\n1.17563\n\n\n13\n13\nσ\nresidual\nmissing\n1.16173\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n489\n489\nσ\nresidual\nmissing\n1.16205\n\n\n490\n490\nσ\nresidual\nmissing\n1.16089\n\n\n491\n491\nσ\nresidual\nmissing\n1.1758\n\n\n492\n492\nσ\nresidual\nmissing\n1.17573\n\n\n493\n493\nσ\nresidual\nmissing\n1.17036\n\n\n494\n494\nσ\nresidual\nmissing\n1.17232\n\n\n495\n495\nσ\nresidual\nmissing\n1.16437\n\n\n496\n496\nσ\nresidual\nmissing\n1.16701\n\n\n497\n497\nσ\nresidual\nmissing\n1.16876\n\n\n498\n498\nσ\nresidual\nmissing\n1.16375\n\n\n499\n499\nσ\nresidual\nmissing\n1.16358\n\n\n500\n500\nσ\nresidual\nmissing\n1.17374\n\n\n\n\n\n\nWe plot the fixed effects:\n\nplt_fe = data(fe) * mapping(:value; layout=:names) * density()\ndraw(plt_fe;\n    facet=(;linkxaxes=:none, linkyaxes=:none))\n\n\n\n\n\n\n\n\nand then tweak the layout a little:\n\nplt_fe = data(fe) * mapping(:value; layout=:names) * density()\nlayout = [(1, 1),\n          (2, 1), (2, 2), (2, 3),\n          (3, 1), (3, 2), (3, 3),\n          (4, 1), (4, 2), (4, 3)]\ndraw(plt_fe;\n    facet=(;linkxaxes=:none, linkyaxes=:none),\n    palettes=(;layout))\n\n\n\n\n\n\n\n\nNext, we plot the random effects:\n\nplt_re = data(re) * mapping(:value; row=:group, col=:names) * density()\ndraw(plt_re; facet=(;linkxaxes=:none, linkyaxes=:none))\n\n\n\n\n\n\n\n\nand the residual SD:\n\nplt_resid = data(resid) * mapping(:value) * density()\ndraw(plt_resid; axis=(;title=\"Residual SD\"))\n\n\n\n\n\n\n\n\nFinally, we put all the plots together into a single figure.\n\nlet f, facet, layout, axis\n    f = Figure(; size=(800, 600))\n    facet = (;linkxaxes=:none, linkyaxes=:none)\n    axis=(; xlabel=\"estimate\")\n    layout = [(1, 1),\n              (2, 1), (2, 2), (2, 3),\n              (3, 1), (3, 2), (3, 3),\n              (4, 1), (4, 2), (4, 3)]\n    Label(f[0, 1], \"Fixed effects\"; tellwidth=false, fontsize=20)\n    draw!(f[1:5, 1], plt_fe; facet, axis, palettes=(;layout))\n    Label(f[0, 2], \"Variance components\"; tellwidth=false, fontsize=20)\n    draw!(f[1:4, 2], plt_re; facet, axis)\n    draw!(f[5, 2], plt_resid; facet, axis)\n    Label(f[end+1, :], \"Density of bootstrapped estimates\", fontsize=30)\n    f\nend",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#mixedmodelsmakie.ridgeplot",
    "href": "04-bootstrap.html#mixedmodelsmakie.ridgeplot",
    "title": "The Parametric Bootstrap",
    "section": "MixedModelsMakie.ridgeplot",
    "text": "MixedModelsMakie.ridgeplot\nMixedModelsMakie defines coefplot for bootstrap objects:\n\nusing MixedModelsMakie\ncoefplot(pb1a; show_intercept=false)\n\n\n\n\n\n\n\n\nThe bootstrap hower provides a much richer estimate of uncertainty, which we can see with ridgeplot:\n\nridgeplot(pb1a)\n\n\n\n\n\n\n\n\nridgeplot supports most of the same options as coefplot (and also has a mutating variant ridgeplot!):\n\nridgeplot(pb1a; show_intercept=false)\n\n\n\n\n\n\n\n\nRidge plots are sometimes also called joy plots in other languages because they look like a certain Joy Division album cover.",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#shortest-coverage-highest-density-interval",
    "href": "04-bootstrap.html#shortest-coverage-highest-density-interval",
    "title": "The Parametric Bootstrap",
    "section": "Shortest coverage / highest density interval",
    "text": "Shortest coverage / highest density interval\nThe default method for the a bootstrapped confidence interval is the shortest (contiguous) coverage interval. Per definition, the shortest coverage interval is also the highest density interval. Note that the confidence interval is always a single interval and never the union of disjoint intervals, which may or may not be desirable for multimodal distribution. However, multimodal distributions should not generally arise in the parametric bootstrap.\n\nconfint(pb1a)\n\nDictTable with 2 columns and 14 rows:\n par   lower      upper\n ────┬──────────────────────\n β01 │ 3.2257     3.35708\n β02 │ 0.0086203  0.0960707\n β03 │ 0.0257096  0.117076\n β04 │ 0.0913164  0.197404\n β05 │ -0.111489  -0.0507315\n β06 │ -0.142169  -0.0771448\n β07 │ -0.235839  -0.156592\n β08 │ -0.217021  -0.12986\n β09 │ -0.286667  -0.204071\n β10 │ -0.101496  -0.0489058\n σ   │ 1.15818    1.18167\n σ1  │ 0.252925   0.439\n σ2  │ 0.471268   1.01893\n σ3  │ 1.01487    1.63069\n\n\n\nconfint(pb1a; method=:shortest)\n\nDictTable with 2 columns and 14 rows:\n par   lower      upper\n ────┬──────────────────────\n β01 │ 3.2257     3.35708\n β02 │ 0.0086203  0.0960707\n β03 │ 0.0257096  0.117076\n β04 │ 0.0913164  0.197404\n β05 │ -0.111489  -0.0507315\n β06 │ -0.142169  -0.0771448\n β07 │ -0.235839  -0.156592\n β08 │ -0.217021  -0.12986\n β09 │ -0.286667  -0.204071\n β10 │ -0.101496  -0.0489058\n σ   │ 1.15818    1.18167\n σ1  │ 0.252925   0.439\n σ2  │ 0.471268   1.01893\n σ3  │ 1.01487    1.63069",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#equal-tail-probability-quantile-interval",
    "href": "04-bootstrap.html#equal-tail-probability-quantile-interval",
    "title": "The Parametric Bootstrap",
    "section": "Equal-tail probability / quantile interval",
    "text": "Equal-tail probability / quantile interval\nThe :equaltail method constructs the confidence that has equal tail probability, which is equivalent to the quantile-based interval. This interval is most comparable to the Wald and profile-based intervals.\n\nconfint(pb1a; method=:equaltail)\n\nDictTable with 2 columns and 14 rows:\n par   lower       upper\n ────┬───────────────────────\n β01 │ 3.22657     3.35983\n β02 │ 0.00330878  0.0949412\n β03 │ 0.0279016   0.119836\n β04 │ 0.0785097   0.192055\n β05 │ -0.110169   -0.0490092\n β06 │ -0.144158   -0.0787608\n β07 │ -0.232093   -0.149827\n β08 │ -0.212548   -0.125297\n β09 │ -0.288305   -0.205441\n β10 │ -0.0997842  -0.0457336\n σ   │ 1.15829     1.18212\n σ1  │ 0.251931    0.438784\n σ2  │ 0.460721    1.01502\n σ3  │ 1.01832     1.6439",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "02-plotting.html",
    "href": "02-plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "Code\nprogress = false\nIn the following, we’ll be using the Makie ecosystem for plottig. There are multiple major plotting ecosystems in Julia and it’s largely a matter of personal preference which to use. However, some plotting tools and packages only exist in one ecosystem, such as MixedModelsMakie.jl for several convenient plotting functions related to MixedModels.jl.\nusing CairoMakie # in Makie, you load a particular backend\nusing MixedModelsMakie\nMost plotting functions come in two variants:\nFollowing the broader convention within Julia, the mutating variants include a ! in their name. It is quite common for the full service variant to be a minimal wrapper around the mutating variant and for the documentation of the full service variant to refer to the mutating variant, stating that all arguments are forwarded. We’ll see a few examples of this pattern in the following.",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#fixed-effects",
    "href": "02-plotting.html#fixed-effects",
    "title": "Plotting",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nThe function coefplot creates a plot of the coefficient estimates along with associated confidence intervals.\n\ncoefplot(fm1)\n\n\n\n\n\n\n\n\nBecause the intercept is often on a different scale than categorical predictors and is not of particular interest, coefplot also has an option for not including it.\n\ncoefplot(fm1; show_intercept=false, color=:red)\n\n\n\n\n\n\n\n\nWe can use the mutating variant coefplot! to put the plots from all models into a single axis for comparison purposes.\n\nlet f = Figure()\n    ax = Axis(f[1, 1]; title=\"Comparison of estimates\")\n    coefplot!(ax, fm1; show_intercept=false, conf_level=0.68, label=\"fm1\")\n    coefplot!(ax, fm2; show_intercept=false, conf_level=0.68, label=\"fm2\")\n    coefplot!(ax, fm3; show_intercept=false, conf_level=0.68, label=\"fm3\")\n    axislegend(ax, \"model\"; merge=true, position=:rb) # _r_ight _b_ottom\n    f\nend",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#blups",
    "href": "02-plotting.html#blups",
    "title": "Plotting",
    "section": "BLUPs",
    "text": "BLUPs\nThe function caterpillar creates a similar plot of the BLUPs and their associated prediction intervals. The name caterpillar comes from the hairy appearance that occurs with large numbers of random effects. In lme4, the comparable plot was called dotplot.\n\n# select the grouping variable we want to plot\ncaterpillar(fm1, :dept)\n\n\n\n\n\n\n\n\nWhen plotting the BLUPs associated with a grouping variable with a very large number of levels, we can use qqcaterpillar, which combines a caterpillar plot a QQ-plot like spacing on the y-axis in order to give a better impression of the distribution of the random effects.\n\nqqcaterpillar(fm1, :dept)\n\n\n\n\n\n\n\n\n\nqqcaterpillar(fm1, :d)\n\n\n\n\n\n\n\n\nWhen a grouping variable is associated with multiple experimental variables, then each receives its own panel in the caterpillar plot.\n\ncaterpillar(fm2, :dept)\n\n\n\n\n\n\n\n\nBy default, the levels of the grouping variable are sorted by their value for the first column. However, we can select which variables are displayed and which column is used for sorting.\n\ncaterpillar(fm2, :dept; cols=[\"(Intercept)\", \"service: Y\"], orderby=2)\n\n\n\n\n\n\n\n\nBecause caterpillar plots can contain multiple axes, they cannot be plotted directly into an axis, but they can be plotted into a GridLayout (i.e. a sublayout) within a Figure.\n\nlet f = Figure(; title=\"Random effects\")\n    caterpillar!(f[1, 1], fm2, :dept)\n    Label(f[0, 1], \"dept\"; tellwidth=false)\n    qqcaterpillar!(f[1, 2], fm2, :d)\n    Label(f[0, 2], \"d(ozent)\"; tellwidth=false)\n    f\nend",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#qq-plots",
    "href": "02-plotting.html#qq-plots",
    "title": "Plotting",
    "section": "QQ Plots",
    "text": "QQ Plots\n\nqqnorm(fm1)\n\n\n\n\n\n\n\n\n\nqqplot(Normal(0, fm1.σ), fm1)",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#multiple-diagnostics",
    "href": "02-plotting.html#multiple-diagnostics",
    "title": "Plotting",
    "section": "Multiple diagnostics",
    "text": "Multiple diagnostics\n\nfunction diagnostic_plot!(f, model)\n    ax = Axis(f[1, 1]; xlabel=\"fitted\", ylabel=\"observed\",\n              title=\"Observed vs fitted\", aspect=AxisAspect(1))\n    scatter!(ax, fitted(model), response(model); alpha=0.5)\n    ablines!(ax, 0, 1; linestyle=:dash)\n\n    ax = Axis(f[1, 2]; xlabel=\"fitted\", ylabel=\"residual\",\n             title=\"Residuals vs fitted\")\n    scatter!(ax, fitted(model), residuals(model); alpha=0.5)\n    hlines!(ax, 0; linestyle=:dash)\n\n    ax = Axis(f[2, 1]; xlabel=\"theoretical quantiles\", ylabel=\"residuals\",\n             title=\"Normal QQ\", aspect=AxisAspect(1))\n    qqnorm!(ax, model)\n\n    ax = Axis(f[2, 2]; xlabel=\"Residual value\", ylabel=\"density\",\n             title=\"Residuals\")\n    density!(ax, residuals(model))\n\n    Label(f[0, :], \"Regression diagnostics\";\n          tellwidth=false, fontsize=24)\n\n    colsize!(f.layout, 1, Auto(0.5))\n\n    return f\nend\n\ndiagnostic_plot!(Figure(), sleep)",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html",
    "href": "99-wilkinson-notation.html",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "“Addition” (+) indicates additive, i.e., main effects: a + b indicates main effects of a and b.\n“Multiplication” (*) indicates crossing: main effects and interactions between two terms: a * b indicates main effects of a and b as well as their interaction.\nUsual algebraic rules apply (associativity and distributivity):\n\n(a + b) * c is equivalent to a * c + b * c\na * b * c corresponds to main effects of a, b, and c, as well as all three two-way interactions and the three-way interaction.\n\nCategorical terms are expanded into the associated indicators/contrast variables.\nTilde (~) is used to separate response from predictors.\nThe intercept is indicated by 1.\ny ~ 1 + (a + b) * c is read as:\n\nThe response variable is y.\nThe model contains an intercept.\nThe model contains main effects of a, b, and c.\nThe model contains interactions between a and c and between b and c but not a and b\n\nWe extend this notation for mixed-effects models with the grouping notation (|):\n\n(1 + a | subject) indicates “by-subject random effects for the intercept and main effect a”.\nThis is in line with the usual statistical reading of | as “conditional on”.\n\n\n\n\n\nModels fit with MixedModels.jl are generally linear mixed-effects models with unconstrained random effects covariance matrices and homoskedastic, normally distributed residuals. Under these assumptions, the model specification\nresponse ~ 1 + (age + sex) * education * n_children  + (1 | subject)\ncorresponds to the statistical model\n\\[\\begin{align*}\n\\left(Y |\\mathcal{B}=b\\right) &\\sim N\\left(X\\beta + Zb, \\sigma^2 I \\right) \\\\\n\\mathcal{B} &\\sim N\\left(0, G\\right)\n\\end{align*}\\]\nfor which we wish to obtain the maximum-likelihood estimates for \\(G\\) and thus the fixed-effects \\(\\beta\\).\n\nThe model contains no restrictions on \\(G\\), except that it is positive semidefinite.\nThe response Y is the value of a given response.\nThe fixed-effects design matrix X consists of columns for\n\nthe intercept, age, sex, education, and number of children (contrast coded as appropriate)\nthe interaction of all lower order terms, excluding interactions between age and sex\n\nThe random-effects design matrix Z includes a column for\n\nthe intercept for each subject",
    "crumbs": [
      "Formula Syntax"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html#general-rules",
    "href": "99-wilkinson-notation.html#general-rules",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "“Addition” (+) indicates additive, i.e., main effects: a + b indicates main effects of a and b.\n“Multiplication” (*) indicates crossing: main effects and interactions between two terms: a * b indicates main effects of a and b as well as their interaction.\nUsual algebraic rules apply (associativity and distributivity):\n\n(a + b) * c is equivalent to a * c + b * c\na * b * c corresponds to main effects of a, b, and c, as well as all three two-way interactions and the three-way interaction.\n\nCategorical terms are expanded into the associated indicators/contrast variables.\nTilde (~) is used to separate response from predictors.\nThe intercept is indicated by 1.\ny ~ 1 + (a + b) * c is read as:\n\nThe response variable is y.\nThe model contains an intercept.\nThe model contains main effects of a, b, and c.\nThe model contains interactions between a and c and between b and c but not a and b\n\nWe extend this notation for mixed-effects models with the grouping notation (|):\n\n(1 + a | subject) indicates “by-subject random effects for the intercept and main effect a”.\nThis is in line with the usual statistical reading of | as “conditional on”.",
    "crumbs": [
      "Formula Syntax"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html#mixed-models-in-wilkinson-rogers-and-mathematical-notation",
    "href": "99-wilkinson-notation.html#mixed-models-in-wilkinson-rogers-and-mathematical-notation",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "Models fit with MixedModels.jl are generally linear mixed-effects models with unconstrained random effects covariance matrices and homoskedastic, normally distributed residuals. Under these assumptions, the model specification\nresponse ~ 1 + (age + sex) * education * n_children  + (1 | subject)\ncorresponds to the statistical model\n\\[\\begin{align*}\n\\left(Y |\\mathcal{B}=b\\right) &\\sim N\\left(X\\beta + Zb, \\sigma^2 I \\right) \\\\\n\\mathcal{B} &\\sim N\\left(0, G\\right)\n\\end{align*}\\]\nfor which we wish to obtain the maximum-likelihood estimates for \\(G\\) and thus the fixed-effects \\(\\beta\\).\n\nThe model contains no restrictions on \\(G\\), except that it is positive semidefinite.\nThe response Y is the value of a given response.\nThe fixed-effects design matrix X consists of columns for\n\nthe intercept, age, sex, education, and number of children (contrast coded as appropriate)\nthe interaction of all lower order terms, excluding interactions between age and sex\n\nThe random-effects design matrix Z includes a column for\n\nthe intercept for each subject",
    "crumbs": [
      "Formula Syntax"
    ]
  },
  {
    "objectID": "03-extensions.html",
    "href": "03-extensions.html",
    "title": "Additional Functionality in Other Packages",
    "section": "",
    "text": "Code\nprogress = false\n\n\nSeveral packages extend the functionality of MixedModels.jl, both in ways specific to mixed models and in ways applicable to more general regression models. In the following, we will use the models from the previous sections to showcase this functionality.\n\nusing MixedModels\n\n\ninsteval = MixedModels.dataset(\"insteval\")\nie1 = fit(MixedModel,\n          @formula(y ~ 1 + studage + lectage + service + (1|s) + (1|d) + (1|dept)),\n          insteval; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2908\n0.0324\n101.45\n&lt;1e-99\n0.3264\n0.5106\n0.0787\n\n\nstudage: 4\n0.0519\n0.0232\n2.24\n0.0249\n\n\n\n\n\nstudage: 6\n0.0721\n0.0240\n3.01\n0.0026\n\n\n\n\n\nstudage: 8\n0.1363\n0.0264\n5.17\n&lt;1e-06\n\n\n\n\n\nlectage: 2\n-0.0808\n0.0154\n-5.25\n&lt;1e-06\n\n\n\n\n\nlectage: 3\n-0.1102\n0.0167\n-6.59\n&lt;1e-10\n\n\n\n\n\nlectage: 4\n-0.1892\n0.0196\n-9.65\n&lt;1e-21\n\n\n\n\n\nlectage: 5\n-0.1644\n0.0214\n-7.68\n&lt;1e-13\n\n\n\n\n\nlectage: 6\n-0.2460\n0.0205\n-12.01\n&lt;1e-32\n\n\n\n\n\nservice: Y\n-0.0727\n0.0135\n-5.40\n&lt;1e-07\n\n\n\n\n\nResidual\n1.1762\n\n\n\n\n\n\n\n\n\n\n\n\nie2 = fit(MixedModel,\n          @formula(y ~ 1 + studage + lectage + service +\n                      (1 | s) +\n                      (1 + service | d) +\n                      (1 + service | dept)),\n          insteval; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2985\n0.0307\n107.27\n&lt;1e-99\n0.3242\n0.5160\n0.0642\n\n\nstudage: 4\n0.0502\n0.0232\n2.16\n0.0306\n\n\n\n\n\nstudage: 6\n0.0573\n0.0242\n2.37\n0.0180\n\n\n\n\n\nstudage: 8\n0.1128\n0.0268\n4.21\n&lt;1e-04\n\n\n\n\n\nlectage: 2\n-0.0787\n0.0156\n-5.03\n&lt;1e-06\n\n\n\n\n\nlectage: 3\n-0.1036\n0.0169\n-6.14\n&lt;1e-09\n\n\n\n\n\nlectage: 4\n-0.1837\n0.0199\n-9.21\n&lt;1e-19\n\n\n\n\n\nlectage: 5\n-0.1503\n0.0217\n-6.94\n&lt;1e-11\n\n\n\n\n\nlectage: 6\n-0.2232\n0.0209\n-10.66\n&lt;1e-25\n\n\n\n\n\nservice: Y\n-0.0281\n0.0498\n-0.56\n0.5732\n\n0.3906\n0.1640\n\n\nResidual\n1.1698\n\n\n\n\n\n\n\n\n\n\n\n\nsleepstudy = MixedModels.dataset(\"sleepstudy\")\nss1 = fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj)), sleepstudy; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n251.4051\n9.5062\n26.45\n&lt;1e-99\n36.0121\n\n\ndays\n10.4673\n0.8017\n13.06\n&lt;1e-38\n\n\n\nResidual\n30.8954\n\n\n\n\n\n\n\n\n\n\nss2 = fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n251.4051\n6.6323\n37.91\n&lt;1e-99\n23.7805\n\n\ndays\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5918\n\n\n\n\n\n\n\n\n\n\nusing DataFrames\ncontra = DataFrame(MixedModels.dataset(\"contra\"))\ncontra[!, :anych] .= contra[!, :livch] .!= \"0\"\ncontrasts = Dict(:livch =&gt; EffectsCoding(; base=\"0\"),\n                 :urban =&gt; HelmertCoding(),\n                 :anych =&gt; HelmertCoding())\ngm1 = fit(MixedModel,\n          @formula(use ~ 1 + urban + anych * age + abs2(age) + (1 | dist & urban)),\n          contra,\n          Bernoulli();\n          contrasts,\n          progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_dist & urban\n\n\n(Intercept)\n-0.3410\n0.1265\n-2.70\n0.0070\n0.5683\n\n\nurban: Y\n0.3934\n0.0853\n4.61\n&lt;1e-05\n\n\n\nanych: true\n0.6065\n0.1045\n5.80\n&lt;1e-08\n\n\n\nage\n-0.0129\n0.0112\n-1.16\n0.2464\n\n\n\nabs2(age)\n-0.0056\n0.0008\n-6.67\n&lt;1e-10\n\n\n\nanych: true & age\n0.0332\n0.0128\n2.59\n0.0095\n\n\n\n\n\n\n\nMixedModelsExtras.jl\nhttps://palday.github.io/MixedModelsExtras.jl/v2\nMixedModelsExtras.jl is a collection of odds-and-ends that may be useful when working with mixed effects models, but which we do not want to include in MixedModels.jl at this time. Some functions may one day migrate to MixedModels.jl, when we are happy with their performance and interface (e.g. vif), but some are intentionally omitted from MixedModels.jl (e.g. r2, adjr2).\n\nusing MixedModelsExtras\n\n\nr2(ss2; conditional=true)\n\n0.8263131631454061\n\n\n\nr2(ss2; conditional=false)\n\n0.28647139510771\n\n\n\nicc(ie2)\n\n0.2885287509497678\n\n\n\nicc(ie2, :dept)\n\n0.01611995223144611\n\n\n\nvif(ie1)\n\n9-element Vector{Float64}:\n 1.514190169564442\n 1.735405720716722\n 1.7822313727377377\n 1.4493789918354905\n 1.4380891655002177\n 1.5948967326558565\n 1.4634021708623473\n 1.8267104465362534\n 1.0161785801934138\n\n\n\nDataFrame(; coef=fixefnames(ie1)[2:end], VIF=vif(ie1))\n\n9×2 DataFrame\n\n\n\nRow\ncoef\nVIF\n\n\n\nString\nFloat64\n\n\n\n\n1\nstudage: 4\n1.51419\n\n\n2\nstudage: 6\n1.73541\n\n\n3\nstudage: 8\n1.78223\n\n\n4\nlectage: 2\n1.44938\n\n\n5\nlectage: 3\n1.43809\n\n\n6\nlectage: 4\n1.5949\n\n\n7\nlectage: 5\n1.4634\n\n\n8\nlectage: 6\n1.82671\n\n\n9\nservice: Y\n1.01618\n\n\n\n\n\n\n\ngvif(ie1)\n\n3-element Vector{Float64}:\n 1.3110871108016546\n 1.3257310755771141\n 1.016178580193414\n\n\n\nDataFrame(; term=termnames(ie1)[2][2:end], GVIF=gvif(ie1))\n\n3×2 DataFrame\n\n\n\nRow\nterm\nGVIF\n\n\n\nString\nFloat64\n\n\n\n\n1\nstudage\n1.31109\n\n\n2\nlectage\n1.32573\n\n\n3\nservice\n1.01618\n\n\n\n\n\n\n\n\nRegressionFormulae.jl\nhttps://github.com/kleinschmidt/RegressionFormulae.jl\nRegressionFormulae.jl provides a few extensions to the somewhat more restricted variant of the Wilkinson-Roger notation found in Julia. In particular, it adds / for nested designs within the fixed effects and ^ for computing interactions only up to a certain order.\n\nusing RegressionFormulae\n\nfit(MixedModel,\n          @formula(y ~ 1 + service / (studage + lectage) +\n                      (1 | s) +\n                      (1 | d) +\n                      (1 | dept)),\n          insteval; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2788\n0.0349\n94.07\n&lt;1e-99\n0.3266\n0.5099\n0.0799\n\n\nservice: Y\n-0.0488\n0.0275\n-1.78\n0.0758\n\n\n\n\n\nservice: N & studage: 4\n0.0904\n0.0275\n3.28\n0.0010\n\n\n\n\n\nservice: Y & studage: 4\n0.0093\n0.0285\n0.33\n0.7442\n\n\n\n\n\nservice: N & studage: 6\n0.0754\n0.0275\n2.74\n0.0062\n\n\n\n\n\nservice: Y & studage: 6\n0.0648\n0.0308\n2.10\n0.0354\n\n\n\n\n\nservice: N & studage: 8\n0.1398\n0.0305\n4.58\n&lt;1e-05\n\n\n\n\n\nservice: Y & studage: 8\n0.1349\n0.0334\n4.04\n&lt;1e-04\n\n\n\n\n\nservice: N & lectage: 2\n-0.0511\n0.0197\n-2.60\n0.0093\n\n\n\n\n\nservice: Y & lectage: 2\n-0.1139\n0.0233\n-4.89\n&lt;1e-05\n\n\n\n\n\nservice: N & lectage: 3\n-0.1065\n0.0211\n-5.06\n&lt;1e-06\n\n\n\n\n\nservice: Y & lectage: 3\n-0.1023\n0.0267\n-3.83\n0.0001\n\n\n\n\n\nservice: N & lectage: 4\n-0.1797\n0.0252\n-7.14\n&lt;1e-12\n\n\n\n\n\nservice: Y & lectage: 4\n-0.1939\n0.0294\n-6.61\n&lt;1e-10\n\n\n\n\n\nservice: N & lectage: 5\n-0.2079\n0.0283\n-7.34\n&lt;1e-12\n\n\n\n\n\nservice: Y & lectage: 5\n-0.1180\n0.0312\n-3.77\n0.0002\n\n\n\n\n\nservice: N & lectage: 6\n-0.2712\n0.0264\n-10.27\n&lt;1e-24\n\n\n\n\n\nservice: Y & lectage: 6\n-0.2268\n0.0293\n-7.74\n&lt;1e-14\n\n\n\n\n\nResidual\n1.1759\n\n\n\n\n\n\n\n\n\n\n\n\nfit(MixedModel,\n          @formula(y ~ 1 + (studage + lectage + service)^2 +\n                      (1 | s) +\n                      (1 | d) +\n                      (1 | dept)),\n          insteval; progress)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2285\n0.0368\n87.85\n&lt;1e-99\n0.3264\n0.5092\n0.0800\n\n\nstudage: 4\n0.1280\n0.0340\n3.77\n0.0002\n\n\n\n\n\nstudage: 6\n0.1525\n0.0343\n4.45\n&lt;1e-05\n\n\n\n\n\nstudage: 8\n0.2326\n0.0399\n5.83\n&lt;1e-08\n\n\n\n\n\nlectage: 2\n0.0554\n0.0302\n1.84\n0.0662\n\n\n\n\n\nlectage: 3\n-0.0273\n0.0640\n-0.43\n0.6702\n\n\n\n\n\nlectage: 4\n-0.1302\n0.0724\n-1.80\n0.0720\n\n\n\n\n\nlectage: 5\n-0.0885\n0.0807\n-1.10\n0.2728\n\n\n\n\n\nlectage: 6\n-0.1707\n0.0836\n-2.04\n0.0411\n\n\n\n\n\nservice: Y\n-0.0364\n0.0278\n-1.31\n0.1912\n\n\n\n\n\nstudage: 4 & lectage: 2\n-0.1117\n0.0400\n-2.80\n0.0052\n\n\n\n\n\nstudage: 6 & lectage: 2\n-0.1638\n0.0397\n-4.13\n&lt;1e-04\n\n\n\n\n\nstudage: 8 & lectage: 2\n-0.1683\n0.0469\n-3.59\n0.0003\n\n\n\n\n\nstudage: 4 & lectage: 3\n-0.1105\n0.0694\n-1.59\n0.1112\n\n\n\n\n\nstudage: 6 & lectage: 3\n-0.1295\n0.0688\n-1.88\n0.0599\n\n\n\n\n\nstudage: 8 & lectage: 3\n-0.0811\n0.0714\n-1.14\n0.2557\n\n\n\n\n\nstudage: 4 & lectage: 4\n0.0420\n0.0765\n0.55\n0.5833\n\n\n\n\n\nstudage: 6 & lectage: 4\n-0.1273\n0.0770\n-1.65\n0.0983\n\n\n\n\n\nstudage: 8 & lectage: 4\n-0.1095\n0.0797\n-1.37\n0.1694\n\n\n\n\n\nstudage: 4 & lectage: 5\n-0.1794\n0.0964\n-1.86\n0.0627\n\n\n\n\n\nstudage: 6 & lectage: 5\n-0.1400\n0.0831\n-1.68\n0.0921\n\n\n\n\n\nstudage: 8 & lectage: 5\n-0.1729\n0.0864\n-2.00\n0.0453\n\n\n\n\n\nstudage: 4 & lectage: 6\n0.0491\n0.0973\n0.50\n0.6137\n\n\n\n\n\nstudage: 6 & lectage: 6\n-0.0834\n0.0853\n-0.98\n0.3282\n\n\n\n\n\nstudage: 8 & lectage: 6\n-0.1821\n0.0867\n-2.10\n0.0358\n\n\n\n\n\nstudage: 4 & service: Y\n-0.0841\n0.0314\n-2.67\n0.0075\n\n\n\n\n\nstudage: 6 & service: Y\n-0.0068\n0.0333\n-0.21\n0.8376\n\n\n\n\n\nstudage: 8 & service: Y\n0.0157\n0.0364\n0.43\n0.6652\n\n\n\n\n\nlectage: 2 & service: Y\n-0.0841\n0.0301\n-2.79\n0.0053\n\n\n\n\n\nlectage: 3 & service: Y\n-0.0031\n0.0342\n-0.09\n0.9277\n\n\n\n\n\nlectage: 4 & service: Y\n-0.0350\n0.0379\n-0.93\n0.3547\n\n\n\n\n\nlectage: 5 & service: Y\n0.0651\n0.0416\n1.56\n0.1176\n\n\n\n\n\nlectage: 6 & service: Y\n0.0137\n0.0376\n0.37\n0.7150\n\n\n\n\n\nResidual\n1.1755\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoxCox.jl\nhttps://palday.github.io/BoxCox.jl/v0.3/\nBoxCox.jl implements a the Box-Cox transformation in an efficient way. Via package extensions, it supports specializations for MixedModels.jl and several plotting functions, but does not incur a dependency penalty for this functionality when MixedModels.jl or Makie.jl are not loaded.\n\nusing BoxCox\n\nbc = fit(BoxCoxTransformation, ss2)\n\nBox-Cox transformation\n\nestimated λ: -1.0747\nresultant transformation:\n\n y^-1.1 - 1\n------------\n    -1.1\n\n\n\nusing CairoMakie\nboxcoxplot(bc; conf_level=0.95)\n\n\n\n\n\n\n\n\nThe estimated λ is very close to -1, i.e. the reciprocal of reaction time, which has a natural interpretation as speed. In other words, the Box-Cox transformation suggests that we should consider modelling the sleepstudy data as speed (reaction per unit time) instead of reaction time:\n\nfit(MixedModel, @formula(1000 / reaction ~ 1 + days + (1 + days|subj)), sleepstudy)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n3.9658\n0.1056\n37.55\n&lt;1e-99\n0.4190\n\n\ndays\n-0.1110\n0.0151\n-7.37\n&lt;1e-12\n0.0566\n\n\nResidual\n0.2698\n\n\n\n\n\n\n\n\n\n(We multiply by 1000 to get the responses per second instead of the responses per millisecond.)\n\n\n\n\n\n\nTip\n\n\n\nBoxCox.jl also works with classical linear models.\n\n\n\n\nEffects.jl\nhttps://beacon-biosignals.github.io/Effects.jl/v1.2/\nEffects.jl provides a convenient method to compute effects, i.e. predictions and associated prediction intervals computed at points on a reference grid. For models with a nonlinear link function, Effects.jl will also compute appropriate errors on the response scale based on the difference method.\nFor MixedModels.jl, the predictions are computed based on the fixed effects only.\nThe functionality of Effects.jl was inspired by the effects and emmeans packages in R and the methods within are based on Fox (2003).\n\nusing Effects\n\n\ndesign = Dict(:age =&gt; -15:1:20,\n              :anych =&gt; [true, false])\n\neff_logit = effects(design, gm1; eff_col=\"use\", level=0.95)\n\n72×6 DataFrame47 rows omitted\n\n\n\nRow\nage\nanych\nuse\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n-15\ntrue\n-1.46982\n0.286496\n-2.03134\n-0.908296\n\n\n2\n-14\ntrue\n-1.28635\n0.257773\n-1.79157\n-0.78112\n\n\n3\n-13\ntrue\n-1.11413\n0.231085\n-1.56704\n-0.661207\n\n\n4\n-12\ntrue\n-0.953158\n0.206515\n-1.35792\n-0.548396\n\n\n5\n-11\ntrue\n-0.803443\n0.184162\n-1.16439\n-0.442493\n\n\n6\n-10\ntrue\n-0.664981\n0.164144\n-0.986698\n-0.343265\n\n\n7\n-9\ntrue\n-0.537772\n0.146597\n-0.825097\n-0.250447\n\n\n8\n-8\ntrue\n-0.421815\n0.131656\n-0.679857\n-0.163773\n\n\n9\n-7\ntrue\n-0.317111\n0.119434\n-0.551197\n-0.0830245\n\n\n10\n-6\ntrue\n-0.223659\n0.109972\n-0.439201\n-0.00811759\n\n\n11\n-5\ntrue\n-0.14146\n0.103193\n-0.343714\n0.060794\n\n\n12\n-4\ntrue\n-0.0705135\n0.0988598\n-0.264275\n0.123248\n\n\n13\n-3\ntrue\n-0.0108196\n0.0965852\n-0.200123\n0.178484\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n61\n9\nfalse\n-1.98338\n0.392298\n-2.75227\n-1.21449\n\n\n62\n10\nfalse\n-2.13644\n0.417895\n-2.9555\n-1.31738\n\n\n63\n11\nfalse\n-2.30076\n0.444744\n-3.17244\n-1.42908\n\n\n64\n12\nfalse\n-2.47632\n0.47289\n-3.40317\n-1.54948\n\n\n65\n13\nfalse\n-2.66314\n0.502378\n-3.64778\n-1.6785\n\n\n66\n14\nfalse\n-2.86121\n0.533247\n-3.90636\n-1.81607\n\n\n67\n15\nfalse\n-3.07054\n0.565536\n-4.17897\n-1.96211\n\n\n68\n16\nfalse\n-3.29111\n0.599276\n-4.46567\n-2.11655\n\n\n69\n17\nfalse\n-3.52294\n0.634497\n-4.76653\n-2.27935\n\n\n70\n18\nfalse\n-3.76602\n0.671226\n-5.0816\n-2.45044\n\n\n71\n19\nfalse\n-4.02036\n0.709487\n-5.41093\n-2.62979\n\n\n72\n20\nfalse\n-4.28594\n0.7493\n-5.75454\n-2.81734\n\n\n\n\n\n\n\neff_prob = effects(design, gm1; eff_col=\"use\", level=0.95, invlink=AutoInvLink())\n\n72×6 DataFrame47 rows omitted\n\n\n\nRow\nage\nanych\nuse\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n-15\ntrue\n0.18697\n0.043551\n0.101612\n0.272329\n\n\n2\n-14\ntrue\n0.216472\n0.0437213\n0.13078\n0.302164\n\n\n3\n-13\ntrue\n0.247103\n0.0429917\n0.16284\n0.331365\n\n\n4\n-12\ntrue\n0.27825\n0.0414738\n0.196963\n0.359537\n\n\n5\n-11\ntrue\n0.309289\n0.0393423\n0.23218\n0.386399\n\n\n6\n-10\ntrue\n0.339621\n0.0368141\n0.267467\n0.411776\n\n\n7\n-9\ntrue\n0.368706\n0.0341222\n0.301828\n0.435584\n\n\n8\n-8\ntrue\n0.396082\n0.0314924\n0.334359\n0.457806\n\n\n9\n-7\ntrue\n0.42138\n0.0291203\n0.364305\n0.478455\n\n\n10\n-6\ntrue\n0.444317\n0.0271521\n0.3911\n0.497534\n\n\n11\n-5\ntrue\n0.464694\n0.0256696\n0.414382\n0.515005\n\n\n12\n-4\ntrue\n0.482379\n0.0246842\n0.433999\n0.530759\n\n\n13\n-3\ntrue\n0.497295\n0.0241456\n0.449971\n0.54462\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n61\n9\nfalse\n0.120959\n0.0417121\n0.0392044\n0.202713\n\n\n62\n10\nfalse\n0.105605\n0.0394712\n0.0282426\n0.182967\n\n\n63\n11\nfalse\n0.0910602\n0.0368107\n0.0189126\n0.163208\n\n\n64\n12\nfalse\n0.0775347\n0.0338225\n0.0112438\n0.143826\n\n\n65\n13\nfalse\n0.0651836\n0.0306122\n0.00518474\n0.125182\n\n\n66\n14\nfalse\n0.0541046\n0.0272901\n0.000616879\n0.107592\n\n\n67\n15\nfalse\n0.0443391\n0.0239635\n-0.00262855\n0.0913067\n\n\n68\n16\nfalse\n0.0358773\n0.020729\n-0.00475083\n0.0765055\n\n\n69\n17\nfalse\n0.0286665\n0.0176674\n-0.00596097\n0.0632939\n\n\n70\n18\nfalse\n0.0226204\n0.01484\n-0.00646538\n0.0517062\n\n\n71\n19\nfalse\n0.0176302\n0.0122878\n-0.00645358\n0.0417139\n\n\n72\n20\nfalse\n0.0135738\n0.0100328\n-0.00609014\n0.0332378\n\n\n\n\n\n\nEffects are particularly nice for visualizing the model fit and its predictions.\n\nusing AlgebraOfGraphics # like ggplot2, but an algebra instead of a grammar\nusing CairoMakie\n\nplt1 = data(eff_logit) *\n      mapping(:age, :use; color=:anych) *\n      (visual(Lines) + mapping(; lower=:lower, upper=:upper) * visual(LinesFill))\ndraw(plt1)\n\n\n\n\n\n\n\n\n\nplt2 = data(eff_prob) *\n      mapping(:age, :use; color=:anych =&gt; \"children\") *\n      (visual(Lines) + mapping(; lower=:lower, upper=:upper) * visual(LinesFill))\ndraw(plt2)\n\n\n\n\n\n\n\n\n\nusing Statistics: mean\ncontra_by_age = transform(contra,\n                          :age =&gt; ByRow(x -&gt; round(Int, x)),\n                          :use =&gt; ByRow(==(\"Y\"));\n                          renamecols=false)\ncontra_by_age = combine(groupby(contra_by_age, [:age, :anych]),\n                        :use =&gt; mean =&gt; :use)\nplt3 = plt2 +\n       data(contra_by_age) *\n       mapping(:age, :use;\n               color=:anych =&gt; \"children\") * visual(Scatter)\n\ndraw(plt3;\n     axis=(; title=\"Estimated contraceptive use by age and children\",\n            limits=(nothing, (0, 1)) # ylim=0,1, xlim=auto\n            ))\n\n\n\n\n\n\n\n\nEffects and estimated marginal (least squares) means are closely related and partially concepts. Effects.jl provides convenience function emmeans and empairs for computing EM means and pairwise differences of EM means.\n\nemmeans(gm1)\n\n4×5 DataFrame\n\n\n\nRow\nage\nurban\nanych\nuse: Y\nerr\n\n\n\nFloat64\nString\nBool\nFloat64\nFloat64\n\n\n\n\n1\n0.00204757\nN\nfalse\n-1.34092\n0.22117\n\n\n2\n0.00204757\nY\nfalse\n-0.554182\n0.229908\n\n\n3\n0.00204757\nN\ntrue\n-0.127828\n0.112245\n\n\n4\n0.00204757\nY\ntrue\n0.658906\n0.149691\n\n\n\n\n\n\n\nempairs(gm1; dof=Inf)\n\n6×8 DataFrame\n\n\n\nRow\nage\nurban\nanych\nuse: Y\nerr\ndof\nt\nPr(&gt;|t|)\n\n\n\nFloat64\nString\nAny\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n0.00204757\nN &gt; Y\nfalse\n-0.786734\n0.31902\nInf\n-2.46609\n0.0136596\n\n\n2\n0.00204757\nN\nfalse &gt; true\n-1.21309\n0.248022\nInf\n-4.89104\n1.00303e-6\n\n\n3\n0.00204757\nN &gt; Y\nfalse &gt; true\n-1.99982\n0.267065\nInf\n-7.48814\n6.98539e-14\n\n\n4\n0.00204757\nY &gt; N\nfalse &gt; true\n-0.426354\n0.255845\nInf\n-1.66645\n0.0956232\n\n\n5\n0.00204757\nY\nfalse &gt; true\n-1.21309\n0.274345\nInf\n-4.42176\n9.79024e-6\n\n\n6\n0.00204757\nN &gt; Y\ntrue\n-0.786734\n0.1871\nInf\n-4.20488\n2.61215e-5\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEffects.jl will work with any package that supports the StatsAPI.jl-based RegressionModel interface.\n\n\n\n\n\nStandardizedPredictors.jl\nhttps://beacon-biosignals.github.io/StandardizedPredictors.jl/v1/\nStandardizedPredictors.jl provides a convenient way to express centering, scaling, and z-standardization as a “contrast” via the pseudo-contrasts Center, Scale, ZScore. Because these use the usual contrast machinery, they work well with any packages that use that machinery correctly (e.g. Effects.jl). The default behavior is to empirically compute the center and scale, but these can also be explicitly provided, either as a number or as a function (e.g. median to use the median for centering.)\n\nusing StandardizedPredictors\n\ncontrasts = Dict(:days =&gt; Center())\nfit(MixedModel,\n    @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy;\n    contrasts)\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n298.5079\n8.7950\n33.94\n&lt;1e-99\n36.4260\n\n\ndays(centered: 4.5)\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5919\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nStandardizedPredictors.jl will work with any package that supports the StatsModels.jl-based @formula and contrast machinery.\n\n\n\n\nRCall.jl and JellyMe4.jl\nhttps://juliainterop.github.io/RCall.jl/stable/\nhttps://github.com/palday/JellyMe4.jl/\nRCall.jl provides a convenient interface for interoperability with R from Julia. JellyMe4.jl extends the functionality of RCall so that MixedModels.jl-fitted models and lme4-fitted models can be translated to each other. In practical terms, this means that you can enjoy the speed of Julia for model fitting, but use all the extra packages you love from R’s larger ecosystem.\n\n\n\nReferences\n\n\nFox, J. (2003). Effect Displays in r for Generalised Linear Models. Journal of Statistical Software, 8(15). https://doi.org/10.18637/jss.v008.i15",
    "crumbs": [
      "Extension Packages"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mixed Effects Models in Julia",
    "section": "",
    "text": "This website contains the course materials for an introduction to mixed effects models in Julia using MixedModels.jl.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Mixed Effects Models in Julia",
    "section": "Prerequisites",
    "text": "Prerequisites\nThe material here assumes a basic proficiency with the Julia language, including a working Julia installation with Julia 1.9+.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#installation-of-course-materials",
    "href": "index.html#installation-of-course-materials",
    "title": "Mixed Effects Models in Julia",
    "section": "Installation of course materials",
    "text": "Installation of course materials\n\nJulia packages used in the examples\nThe source code for everything can be downloaded from GitHub. After downloading the materials, you should install the necessary Julia packages.\n\n\n\n\n\n\nTip\n\n\n\nWhen copying and pasting into the Julia REPL, you don’t need to remove the julia&gt; prompt from the examples. The Julia REPL will detect the prompt and strip it for you.\n\n\nFeel free to skip the movielens_download step – the relevant examples are provided only to show scaling with very large datasets.\n~/economics2024$ julia\n\njulia&gt; using Pkg\n\njulia&gt; Pkg.activate(\".\")\n  Activating project at `~/economics2024`\n\njulia&gt; Pkg.instantiate()\n&lt; lots of output &gt;\n\njulia&gt; using Econ2024\n\njulia&gt; Econ2024.movielens_download() # note: this is a very large dataset!\n[ Info: Downloading data\n[ Info: Extracting and saving ratings\n[ Info: Extracting movies that are in the ratings table\n[ Info: Extracting and saving README\n2-element Vector{String}:\n \"~/.julia/scratchspa\" ⋯ 28 bytes ⋯ \"3d4d5d689f47/data/ratings.arrow\"\n \"~/.julia/scratchspa\" ⋯ 27 bytes ⋯ \"-3d4d5d689f47/data/movies.arrow\"\n\njulia&gt; exit()\nIf your receive a precompilation error for RCall or JellyMe4, you won’t be able to use those packages, but should be able complete all other examples. The most likely cause of the precompilation error is a problem with RCall’s configuration for using R from within Julia.\n\n\n\n\n\n\nImportant\n\n\n\nPlease check that you have the most recent version of the materials directly before the course.\n\n\n\n\nRendering the course website\nThis repository uses Quarto with the Julia code execution supplied by QuartoNotebookRunner.jl, which requires Quarto 1.5+.\nAs of early May 2024, Quarto 1.5 is only available as a preview release, which you’ll need to download from GitHub. Under each release’s “Assets”, you can find platform-specific installers.\n\n\n\n\n\n\nTip\n\n\n\nYou don’t need to install or use quarto to view the course materials. Everything, including the example code, is visible on the website, with links to the underlying source code for the entire page.\n\n\n~/economics2024$ quarto preview\n\n&lt; lots of output &gt;\n\nThis page was rendered from git revision 0162363\n.",
    "crumbs": [
      "Home"
    ]
  }
]