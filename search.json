[
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "MixedModels.jl is part of the JuliaStats ecosystem and so shares a number of interface and design elements with GLM.jl. MixedModels.jl can also be viewed as the next step in the research programme behind the R package lme4 (and further back, nlme). The focus of development is on linear mixed effects models with unconstrained covariance matrices, with a secondary focus on generalized linear mixed effects models. We’ll come back to this focus later, when we discuss limitations of the software. For now, let us start off with a simple mixed model.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#optimization-results",
    "href": "01-intro.html#optimization-results",
    "title": "Introduction",
    "section": "Optimization results",
    "text": "Optimization results\nFor more technically oriented users and debugging problematic models, the fitted model also includes information about its fit:\n\nfm1.optsum\n\n\n\n\n\n\n\n\n\nInitialization\n\n\n\nInitial parameter vector\n[1.0, 1.0, 1.0]\n\n\nInitial objective value\n241905.85361894374\n\n\nOptimizer settings\n\n\n\nOptimizer (from NLopt)\nLN_BOBYQA\n\n\nLower bounds\n[0.0, 0.0, 0.0]\n\n\nftol_rel\n1.0e-12\n\n\nftol_abs\n1.0e-8\n\n\nxtol_rel\n0.0\n\n\nxtol_abs\n[1.0e-10, 1.0e-10, 1.0e-10]\n\n\ninitial_step\n[0.75, 0.75, 0.75]\n\n\nmaxfeval\n-1\n\n\nmaxtime\n-1.0\n\n\nResult\n\n\n\nFunction evaluations\n97\n\n\nFinal parameter vector\n[0.2775, 0.4341, 0.0669]\n\n\nFinal objective value\n237553.9858\n\n\nReturn code\nFTOL_REACHED",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#best-linear-unbiased-predictions",
    "href": "01-intro.html#best-linear-unbiased-predictions",
    "title": "Introduction",
    "section": "Best linear unbiased predictions",
    "text": "Best linear unbiased predictions\nWe can also examine the best linear unbiased predictions (BLUPS, i.e. conditional modes) of the fitted model:\n\nranef(fm1) # gives a compact mathematical representation\n\n3-element Vector{Matrix{Float64}}:\n [0.16774140235737575 -0.04482701285162444 … 0.1382442938500027 0.2650774864010803]\n [0.3871977014122401 -0.4543515141805431 … 0.5663070246200219 -0.2322550813384579]\n [0.01925209823588375 -0.03142469083851408 … -0.03943347505732836 0.010869167979893487]\n\n\n\nre = raneftables(fm1) # gives a NamedTuple of tables for each grouping variable\n\n(s = @NamedTuple{s::String, (Intercept)::Float64}[(s = \"S0001\", var\"(Intercept)\" = 0.16774140235737575), (s = \"S0002\", var\"(Intercept)\" = -0.04482701285162444), (s = \"S0003\", var\"(Intercept)\" = 0.31575935321258014), (s = \"S0004\", var\"(Intercept)\" = 0.24940732776784375), (s = \"S0005\", var\"(Intercept)\" = 0.050863352996870996), (s = \"S0006\", var\"(Intercept)\" = 0.10070590858725184), (s = \"S0007\", var\"(Intercept)\" = 0.49346379654842415), (s = \"S0008\", var\"(Intercept)\" = 0.21230071437874554), (s = \"S0009\", var\"(Intercept)\" = 0.4332979595948472), (s = \"S0010\", var\"(Intercept)\" = 0.34743864199091984)  …  (s = \"S2963\", var\"(Intercept)\" = -0.0749327557261207), (s = \"S2964\", var\"(Intercept)\" = -0.07639856541116313), (s = \"S2965\", var\"(Intercept)\" = -0.012697609893877363), (s = \"S2966\", var\"(Intercept)\" = -0.059683628597548756), (s = \"S2967\", var\"(Intercept)\" = -0.4776209481575346), (s = \"S2968\", var\"(Intercept)\" = -0.038080766921188454), (s = \"S2969\", var\"(Intercept)\" = 0.013164291227622239), (s = \"S2970\", var\"(Intercept)\" = 0.15284748072859305), (s = \"S2971\", var\"(Intercept)\" = 0.1382442938500027), (s = \"S2972\", var\"(Intercept)\" = 0.2650774864010803)], d = @NamedTuple{d::String, (Intercept)::Float64}[(d = \"I0001\", var\"(Intercept)\" = 0.3871977014122401), (d = \"I0006\", var\"(Intercept)\" = -0.4543515141805431), (d = \"I0007\", var\"(Intercept)\" = 0.6941271319185779), (d = \"I0008\", var\"(Intercept)\" = -0.6556985316701274), (d = \"I0012\", var\"(Intercept)\" = 0.2232270929725692), (d = \"I0013\", var\"(Intercept)\" = 0.35851765095513616), (d = \"I0014\", var\"(Intercept)\" = 0.36727982802972875), (d = \"I0015\", var\"(Intercept)\" = -0.37841262336526776), (d = \"I0017\", var\"(Intercept)\" = 0.4490431092879482), (d = \"I0018\", var\"(Intercept)\" = -0.2130290212029939)  …  (d = \"I2143\", var\"(Intercept)\" = 0.46453563052639246), (d = \"I2145\", var\"(Intercept)\" = -0.5103159237956026), (d = \"I2146\", var\"(Intercept)\" = 0.24093840057454008), (d = \"I2147\", var\"(Intercept)\" = -0.609469079727866), (d = \"I2149\", var\"(Intercept)\" = -0.2569369866698443), (d = \"I2152\", var\"(Intercept)\" = -0.14863445582416115), (d = \"I2153\", var\"(Intercept)\" = -0.45824502947271933), (d = \"I2156\", var\"(Intercept)\" = -0.5981638095970262), (d = \"I2157\", var\"(Intercept)\" = 0.5663070246200219), (d = \"I2160\", var\"(Intercept)\" = -0.2322550813384579)], dept = @NamedTuple{dept::String, (Intercept)::Float64}[(dept = \"D01\", var\"(Intercept)\" = 0.01925209823588375), (dept = \"D02\", var\"(Intercept)\" = -0.03142469083851408), (dept = \"D03\", var\"(Intercept)\" = 0.026990446729129435), (dept = \"D04\", var\"(Intercept)\" = 0.08635016621351274), (dept = \"D05\", var\"(Intercept)\" = 0.04253962436019779), (dept = \"D06\", var\"(Intercept)\" = -0.06123971074400431), (dept = \"D07\", var\"(Intercept)\" = 0.03799512248138028), (dept = \"D08\", var\"(Intercept)\" = 0.10707218145634924), (dept = \"D09\", var\"(Intercept)\" = -0.031304654966880036), (dept = \"D10\", var\"(Intercept)\" = -0.1307501138466036), (dept = \"D11\", var\"(Intercept)\" = -0.05345402697344361), (dept = \"D12\", var\"(Intercept)\" = 0.01653786497082539), (dept = \"D14\", var\"(Intercept)\" = -0.03943347505732836), (dept = \"D15\", var\"(Intercept)\" = 0.010869167979893487)])\n\n\n\nre[:dept]\n\nTable with 2 columns and 14 rows:\n      dept  (Intercept)\n    ┌──────────────────\n 1  │ D01   0.0192521\n 2  │ D02   -0.0314247\n 3  │ D03   0.0269904\n 4  │ D04   0.0863502\n 5  │ D05   0.0425396\n 6  │ D06   -0.0612397\n 7  │ D07   0.0379951\n 8  │ D08   0.107072\n 9  │ D09   -0.0313047\n 10 │ D10   -0.13075\n 11 │ D11   -0.053454\n 12 │ D12   0.0165379\n 13 │ D14   -0.0394335\n 14 │ D15   0.0108692\n\n\nSimilarly, condVar and condVartables provide similar results for the conditional variances, which can be used to construct prediction intervals. Note that this quantity is slightly more challenging to compute, so the next code chunk can be quite slow for large and/or complex models.\n\ncv = condVartables(fm1)\n\n(s = (s = [\"S0001\", \"S0002\", \"S0003\", \"S0004\", \"S0005\", \"S0006\", \"S0007\", \"S0008\", \"S0009\", \"S0010\"  …  \"S2963\", \"S2964\", \"S2965\", \"S2966\", \"S2967\", \"S2968\", \"S2969\", \"S2970\", \"S2971\", \"S2972\"], σ = [(0.2858671228362245,), (0.3040165017502583,), (0.22821165533498675,), (0.2578004425103726,), (0.2860221041711748,), (0.25793963311878376,), (0.2649009415162111,), (0.27833696665010815,), (0.2522474519336828,), (0.22880839419265198,)  …  (0.20261432307540148,), (0.15345463114059987,), (0.18906069725437913,), (0.23644930010448192,), (0.16864269562394849,), (0.132482319658741,), (0.21568697330755854,), (0.15989935597851845,), (0.1970392691204506,), (0.17611124660034733,)], ρ = [(), (), (), (), (), (), (), (), (), ()  …  (), (), (), (), (), (), (), (), (), ()]), d = (d = [\"I0001\", \"I0006\", \"I0007\", \"I0008\", \"I0012\", \"I0013\", \"I0014\", \"I0015\", \"I0017\", \"I0018\"  …  \"I2143\", \"I2145\", \"I2146\", \"I2147\", \"I2149\", \"I2152\", \"I2153\", \"I2156\", \"I2157\", \"I2160\"], σ = [(0.29447193578517417,), (0.1998489863854152,), (0.19760667793253092,), (0.1527043969316495,), (0.20500621849854034,), (0.18323915120884238,), (0.20826361545342348,), (0.1379769401014668,), (0.0991637673510267,), (0.2589837320741506,)  …  (0.2709897676057369,), (0.27856001288516263,), (0.2642022156832947,), (0.1135259649977105,), (0.21483200256076004,), (0.28061051441897883,), (0.21640462394420396,), (0.26558786177554317,), (0.18875478926313752,), (0.12464418506317759,)], ρ = [(), (), (), (), (), (), (), (), (), ()  …  (), (), (), (), (), (), (), (), (), ()]), dept = (dept = [\"D01\", \"D02\", \"D03\", \"D04\", \"D05\", \"D06\", \"D07\", \"D08\", \"D09\", \"D10\", \"D11\", \"D12\", \"D14\", \"D15\"], σ = [(0.05342326269418921,), (0.056952844171391834,), (0.053094116815828214,), (0.041891800931267716,), (0.055366070778972126,), (0.04470931534818489,), (0.05357594671331021,), (0.05037357874667522,), (0.05202188180710211,), (0.04767962130821475,), (0.052241617344059924,), (0.04219066031585405,), (0.05298726732192016,), (0.04862598365500502,)], ρ = [(), (), (), (), (), (), (), (), (), (), (), (), (), ()]))\n\n\n\n# this output still isn't pretty, but we're working on it!\ncv[:dept]\n\n(dept = [\"D01\", \"D02\", \"D03\", \"D04\", \"D05\", \"D06\", \"D07\", \"D08\", \"D09\", \"D10\", \"D11\", \"D12\", \"D14\", \"D15\"], σ = [(0.05342326269418921,), (0.056952844171391834,), (0.053094116815828214,), (0.041891800931267716,), (0.055366070778972126,), (0.04470931534818489,), (0.05357594671331021,), (0.05037357874667522,), (0.05202188180710211,), (0.04767962130821475,), (0.052241617344059924,), (0.04219066031585405,), (0.05298726732192016,), (0.04862598365500502,)], ρ = [(), (), (), (), (), (), (), (), (), (), (), (), (), ()])\n\n\nAt this point, it becomes convenient to place everything into a dataframe so that we can easily manipulate the relevant quantities.\n\nusing DataFrames\ndept = DataFrame(cv[:dept])\n\n\n14×3 DataFrame\n\n\n\nRow\ndept\nσ\nρ\n\n\n\nString\nTuple…\nTuple{}\n\n\n\n\n1\nD01\n(0.0534233,)\n()\n\n\n2\nD02\n(0.0569528,)\n()\n\n\n3\nD03\n(0.0530941,)\n()\n\n\n4\nD04\n(0.0418918,)\n()\n\n\n5\nD05\n(0.0553661,)\n()\n\n\n6\nD06\n(0.0447093,)\n()\n\n\n7\nD07\n(0.0535759,)\n()\n\n\n8\nD08\n(0.0503736,)\n()\n\n\n9\nD09\n(0.0520219,)\n()\n\n\n10\nD10\n(0.0476796,)\n()\n\n\n11\nD11\n(0.0522416,)\n()\n\n\n12\nD12\n(0.0421907,)\n()\n\n\n13\nD14\n(0.0529873,)\n()\n\n\n14\nD15\n(0.048626,)\n()\n\n\n\n\n\n\n\nLet’s construct prediction intervals:\n\nselect!(dept, :dept, :σ =&gt; ByRow(first) =&gt; :condvar)\nleftjoin!(dept, DataFrame(re[:dept]); on=:dept)\n\n\n14×3 DataFrame\n\n\n\nRow\ndept\ncondvar\n(Intercept)\n\n\n\nString\nFloat64\nFloat64?\n\n\n\n\n1\nD01\n0.0534233\n0.0192521\n\n\n2\nD02\n0.0569528\n-0.0314247\n\n\n3\nD03\n0.0530941\n0.0269904\n\n\n4\nD04\n0.0418918\n0.0863502\n\n\n5\nD05\n0.0553661\n0.0425396\n\n\n6\nD06\n0.0447093\n-0.0612397\n\n\n7\nD07\n0.0535759\n0.0379951\n\n\n8\nD08\n0.0503736\n0.107072\n\n\n9\nD09\n0.0520219\n-0.0313047\n\n\n10\nD10\n0.0476796\n-0.13075\n\n\n11\nD11\n0.0522416\n-0.053454\n\n\n12\nD12\n0.0421907\n0.0165379\n\n\n13\nD14\n0.0529873\n-0.0394335\n\n\n14\nD15\n0.048626\n0.0108692\n\n\n\n\n\n\n\n\nselect!(dept, \"dept\", \"(Intercept)\" =&gt; \"blup\", \"condvar\")\ntransform!(dept,\n           [:blup, :condvar] =&gt; ByRow((x,y) -&gt; x - 1.96 * y) =&gt; :lower,\n           [:blup, :condvar] =&gt; ByRow((x,y) -&gt; x + 1.96 * y) =&gt; :upper)\n\n\n14×5 DataFrame\n\n\n\nRow\ndept\nblup\ncondvar\nlower\nupper\n\n\n\nString\nFloat64?\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\nD01\n0.0192521\n0.0534233\n-0.0854575\n0.123962\n\n\n2\nD02\n-0.0314247\n0.0569528\n-0.143052\n0.0802029\n\n\n3\nD03\n0.0269904\n0.0530941\n-0.077074\n0.131055\n\n\n4\nD04\n0.0863502\n0.0418918\n0.00424224\n0.168458\n\n\n5\nD05\n0.0425396\n0.0553661\n-0.0659779\n0.151057\n\n\n6\nD06\n-0.0612397\n0.0447093\n-0.14887\n0.0263905\n\n\n7\nD07\n0.0379951\n0.0535759\n-0.0670137\n0.143004\n\n\n8\nD08\n0.107072\n0.0503736\n0.00833997\n0.205804\n\n\n9\nD09\n-0.0313047\n0.0520219\n-0.133268\n0.0706582\n\n\n10\nD10\n-0.13075\n0.0476796\n-0.224202\n-0.0372981\n\n\n11\nD11\n-0.053454\n0.0522416\n-0.155848\n0.0489395\n\n\n12\nD12\n0.0165379\n0.0421907\n-0.0661558\n0.0992316\n\n\n13\nD14\n-0.0394335\n0.0529873\n-0.143289\n0.0644216\n\n\n14\nD15\n0.0108692\n0.048626\n-0.0844378\n0.106176",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#measures-of-model-fit",
    "href": "01-intro.html#measures-of-model-fit",
    "title": "Introduction",
    "section": "Measures of model fit",
    "text": "Measures of model fit\nMixedModels.jl provides methods for the standard functions aic, aicc, bic, deviance, fitted, logliklihood, nobs, residuals.\nThe deviance is computed as -2 loglikelihood and is thus missing an additive constant for the saturated model. However, defining that constant is challenging for mixed models (what is the saturated model? do you saturate via the fixed or the random effects?) and that constant cancels out in the relevant computations.\nMixedModels.jl intentionally does not provide methods for r2 and adjr2. These quantities are notoriously difficult to define in a completely satisfactory way for mixed models and we, the developers, felt uncomfortable giving our implicit endorsement by defining them as part of the core package. That said, there is an implementation of a naive definition of the coefficient of determination in MixedModelsExtras.jl because it is a commonly requested measure and I felt that it was better to have a well-tested implementation than have users handroll their own buggy implementation of an already problematic measure.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#memory-allocation-vs.-fitting",
    "href": "01-intro.html#memory-allocation-vs.-fitting",
    "title": "Introduction",
    "section": "Memory allocation vs. fitting",
    "text": "Memory allocation vs. fitting\n\nusing Econ2024\nratings = Econ2024.dataset(\"ratings\")\n@time fm_ratings = LinearMixedModel(@formula(rating ~ 1 + (1|userId) + (1|movieId)), ratings)\n\n\n@time fit!(fm_ratings)",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#to-try-on-your-own-after-the-course",
    "href": "01-intro.html#to-try-on-your-own-after-the-course",
    "title": "Introduction",
    "section": "To try on your own after the course",
    "text": "To try on your own after the course\n\nusing Econ2024\nratings = DataFrame(Econ2024.dataset(\"ratings_genre\"))\ndescribe(ratings)\n\n\nusing StatsBase\nmcount = countmap(ratings.movieId)\nucount = countmap(ratings.userId)\nmexclude = Set(k for (k, v) in pairs(mcount) if v &lt; 50)\nuexclude = Set(k for (k, v) in pairs(ucount) if v &lt; 50)\nratings = subset(ratings,\n                 :movieId =&gt; ByRow(!in(mexclude)),\n                 :userId =&gt; ByRow(!in(uexclude)))\n\n\n# This takes about an hour on my home computer when using the full dataset\nform1 = @formula(rating ~ 0 + Action + Adventure + Animation +\n                             Children + Comedy + Crime +\n                             Documentary + Drama +\n                             Fantasy + Film_Noir +\n                             Horror + IMAX +\n                             Musical + Mystery + Romance +\n                             Sci_Fi + Thriller + War + Western +\n                             (1 | movieId) +\n                             (1 | userId))\nfit(MixedModel, form1, ratings)",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#very-few-options-for-covariance-structure",
    "href": "01-intro.html#very-few-options-for-covariance-structure",
    "title": "Introduction",
    "section": "Very few options for covariance structure",
    "text": "Very few options for covariance structure\nNonetheless, there is no free lunch and the tradeoff that we make is that it is much more difficult to formulate constraints on the covariance structure (whether on the random effects or on the response/residuals) in our formulation. MixedModels.jl currently supports precisely two covariance structures explicitly:\n\nunconstrained\nzero correlation (diagonal covariance structure)\n\nIt is also possible to express some models with compound symmetry by clever manipulation of the formula syntax (i.e. (1+c|g) for categorical c with compound symmetry is the same as (1|g) + (1|g&c)).\nMixedModels.jl does support constraining the residual variance to known scalar value, which is useful in meta-analysis.\nMetida.jl may provide an alternative if this functionality is required (not an endorsement).",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-generalized-linear-mixed-models-with-a-dispersion-parameter",
    "href": "01-intro.html#no-support-for-generalized-linear-mixed-models-with-a-dispersion-parameter",
    "title": "Introduction",
    "section": "No support for generalized linear mixed models with a dispersion parameter",
    "text": "No support for generalized linear mixed models with a dispersion parameter\nWhile MixedModels.jl does nominally support any GLM family and link function support by GLM.jl, the results for model families with a dispersion parameter (normal with non-identity link, gamma, inverse Gaussian) are known to be incorrect. The package issues a warning if you attempt to fit such models.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-polytomous-responses",
    "href": "01-intro.html#no-support-for-polytomous-responses",
    "title": "Introduction",
    "section": "No support for polytomous responses",
    "text": "No support for polytomous responses\nMultinomial and ordered responses are not supported. I am unaware of a Julia package offering support for this.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-regularization-of-the-fixed-effects",
    "href": "01-intro.html#no-support-for-regularization-of-the-fixed-effects",
    "title": "Introduction",
    "section": "No support for regularization of the fixed effects",
    "text": "No support for regularization of the fixed effects\nHighDimMixedModels.jl may provide an alternative if this functionality is required (not an endorsement).",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-generalized-additive-mixed-models",
    "href": "01-intro.html#no-support-for-generalized-additive-mixed-models",
    "title": "Introduction",
    "section": "No support for generalized additive mixed models",
    "text": "No support for generalized additive mixed models\nGeneralized additive models can be expressed a mixed model, so supporting this would require “only” adding a translation layer.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "01-intro.html#no-support-for-nonlinear-mixed-effects-models",
    "href": "01-intro.html#no-support-for-nonlinear-mixed-effects-models",
    "title": "Introduction",
    "section": "No support for nonlinear mixed effects models",
    "text": "No support for nonlinear mixed effects models\nPumas.jl (commercial) provides this.",
    "crumbs": [
      "MixedModels.jl"
    ]
  },
  {
    "objectID": "03-extensions.html",
    "href": "03-extensions.html",
    "title": "Additional Functionality in Other Packages",
    "section": "",
    "text": "Code\nprogress = false\n\n\nSeveral packages extend the functionality of MixedModels.jl, both in ways specific to mixed models and in ways applicable to more general regression models. In the following, we will use the models from the previous sections to showcase this functionality.\n\nusing MixedModels\n\n\ninsteval = MixedModels.dataset(\"insteval\")\nie1 = fit(MixedModel,\n          @formula(y ~ 1 + studage + lectage + service + (1|s) + (1|d) + (1|dept)),\n          insteval; progress)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2908\n0.0324\n101.45\n&lt;1e-99\n0.3264\n0.5106\n0.0787\n\n\nstudage: 4\n0.0519\n0.0232\n2.24\n0.0249\n\n\n\n\n\nstudage: 6\n0.0721\n0.0240\n3.01\n0.0026\n\n\n\n\n\nstudage: 8\n0.1363\n0.0264\n5.17\n&lt;1e-06\n\n\n\n\n\nlectage: 2\n-0.0808\n0.0154\n-5.25\n&lt;1e-06\n\n\n\n\n\nlectage: 3\n-0.1102\n0.0167\n-6.59\n&lt;1e-10\n\n\n\n\n\nlectage: 4\n-0.1892\n0.0196\n-9.65\n&lt;1e-21\n\n\n\n\n\nlectage: 5\n-0.1644\n0.0214\n-7.68\n&lt;1e-13\n\n\n\n\n\nlectage: 6\n-0.2460\n0.0205\n-12.01\n&lt;1e-32\n\n\n\n\n\nservice: Y\n-0.0727\n0.0135\n-5.40\n&lt;1e-07\n\n\n\n\n\nResidual\n1.1762\n\n\n\n\n\n\n\n\n\n\n\n\n\nie2 = fit(MixedModel,\n          @formula(y ~ 1 + studage + lectage + service +\n                      (1 | s) +\n                      (1 + service | d) +\n                      (1 + service | dept)),\n          insteval; progress)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2985\n0.0308\n107.26\n&lt;1e-99\n0.3242\n0.5160\n0.0642\n\n\nstudage: 4\n0.0502\n0.0232\n2.16\n0.0306\n\n\n\n\n\nstudage: 6\n0.0573\n0.0242\n2.37\n0.0180\n\n\n\n\n\nstudage: 8\n0.1128\n0.0268\n4.21\n&lt;1e-04\n\n\n\n\n\nlectage: 2\n-0.0787\n0.0156\n-5.03\n&lt;1e-06\n\n\n\n\n\nlectage: 3\n-0.1036\n0.0169\n-6.14\n&lt;1e-09\n\n\n\n\n\nlectage: 4\n-0.1837\n0.0199\n-9.21\n&lt;1e-19\n\n\n\n\n\nlectage: 5\n-0.1503\n0.0217\n-6.94\n&lt;1e-11\n\n\n\n\n\nlectage: 6\n-0.2232\n0.0209\n-10.66\n&lt;1e-25\n\n\n\n\n\nservice: Y\n-0.0281\n0.0498\n-0.56\n0.5731\n\n0.3906\n0.1639\n\n\nResidual\n1.1698\n\n\n\n\n\n\n\n\n\n\n\n\n\nsleepstudy = MixedModels.dataset(\"sleepstudy\")\nss1 = fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj)), sleepstudy)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n251.4051\n9.5062\n26.45\n&lt;1e-99\n36.0121\n\n\ndays\n10.4673\n0.8017\n13.06\n&lt;1e-38\n\n\n\nResidual\n30.8954\n\n\n\n\n\n\n\n\n\n\n\nss2 = fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n251.4051\n6.6323\n37.91\n&lt;1e-99\n23.7805\n\n\ndays\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5918\n\n\n\n\n\n\n\n\n\n\n\nusing DataFrames\ncontra = DataFrame(MixedModels.dataset(\"contra\"))\ncontra[!, :anych] .= contra[!, :livch] .!= \"0\"\ncontrasts = Dict(:livch =&gt; EffectsCoding(; base=\"0\"),\n                 :urban =&gt; HelmertCoding(),\n                 :anych =&gt; HelmertCoding())\ngm1 = fit(MixedModel,\n          @formula(use ~ 1 + urban + anych * age + abs2(age) + (1 | dist & urban)),\n          contra,\n          Bernoulli();\n          contrasts,\n          progress)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_dist & urban\n\n\n(Intercept)\n-0.3410\n0.1265\n-2.70\n0.0070\n0.5682\n\n\nurban: Y\n0.3934\n0.0853\n4.61\n&lt;1e-05\n\n\n\nanych: true\n0.6064\n0.1045\n5.80\n&lt;1e-08\n\n\n\nage\n-0.0129\n0.0112\n-1.16\n0.2465\n\n\n\nabs2(age)\n-0.0056\n0.0008\n-6.67\n&lt;1e-10\n\n\n\nanych: true & age\n0.0332\n0.0128\n2.59\n0.0095\n\n\n\n\n\n\n\n\nMixedModelsExtras.jl\nhttps://palday.github.io/MixedModelsExtras.jl/v2\nMixedModelsExtras.jl is a collection of odds-and-ends that may be useful when working with mixed effects models, but which we do not want to include in MixedModels.jl at this time. Some functions may one day migrate to MixedModels.jl, when we are happy with their performance and interface (e.g. vif), but some are intentionally omitted from MixedModels.jl (e.g. r2, adjr2).\n\nusing MixedModelsExtras\n\n\nr2(ss2; conditional=true)\n\n0.8263131642760502\n\n\n\nr2(ss2; conditional=false)\n\n0.28647139510771\n\n\n\nicc(ie2)\n\n0.28853116879804486\n\n\n\nicc(ie2, :dept)\n\n0.016119387658148597\n\n\n\nvif(ie1)\n\n9-element Vector{Float64}:\n 1.514189953373784\n 1.7354052063945073\n 1.782230800039364\n 1.4493788224538782\n 1.43808916649895\n 1.594896527717326\n 1.4634020652231683\n 1.8267101123046552\n 1.0161785707996789\n\n\n\nDataFrame(; coef=fixefnames(ie1)[2:end], VIF=vif(ie1))\n\n\n9×2 DataFrame\n\n\n\nRow\ncoef\nVIF\n\n\n\nString\nFloat64\n\n\n\n\n1\nstudage: 4\n1.51419\n\n\n2\nstudage: 6\n1.73541\n\n\n3\nstudage: 8\n1.78223\n\n\n4\nlectage: 2\n1.44938\n\n\n5\nlectage: 3\n1.43809\n\n\n6\nlectage: 4\n1.5949\n\n\n7\nlectage: 5\n1.4634\n\n\n8\nlectage: 6\n1.82671\n\n\n9\nservice: Y\n1.01618\n\n\n\n\n\n\n\n\ngvif(ie1)\n\n3-element Vector{Float64}:\n 1.3110868052852684\n 1.3257307677249577\n 1.016178570799679\n\n\n\nDataFrame(; term=termnames(ie1)[2][2:end], GVIF=gvif(ie1))\n\n\n3×2 DataFrame\n\n\n\nRow\nterm\nGVIF\n\n\n\nString\nFloat64\n\n\n\n\n1\nstudage\n1.31109\n\n\n2\nlectage\n1.32573\n\n\n3\nservice\n1.01618\n\n\n\n\n\n\n\n\n\nRegressionFormulae.jl\nhttps://github.com/kleinschmidt/RegressionFormulae.jl\nRegressionFormulae.jl provides a few extensions to the somewhat more restricted variant of the Wilkinson-Roger notation found in Julia. In particular, it adds / for nested designs within the fixed effects and ^ for computing interactions only up to a certain order.\n\nusing RegressionFormulae\n\nfit(MixedModel,\n          @formula(y ~ 1 + service / (studage + lectage) +\n                      (1 | s) +\n                      (1 | d) +\n                      (1 | dept)),\n          insteval; progress)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2788\n0.0349\n94.06\n&lt;1e-99\n0.3266\n0.5099\n0.0799\n\n\nservice: Y\n-0.0488\n0.0275\n-1.78\n0.0758\n\n\n\n\n\nservice: N & studage: 4\n0.0904\n0.0275\n3.28\n0.0010\n\n\n\n\n\nservice: Y & studage: 4\n0.0093\n0.0285\n0.33\n0.7442\n\n\n\n\n\nservice: N & studage: 6\n0.0754\n0.0275\n2.74\n0.0062\n\n\n\n\n\nservice: Y & studage: 6\n0.0648\n0.0308\n2.10\n0.0354\n\n\n\n\n\nservice: N & studage: 8\n0.1398\n0.0305\n4.58\n&lt;1e-05\n\n\n\n\n\nservice: Y & studage: 8\n0.1349\n0.0334\n4.04\n&lt;1e-04\n\n\n\n\n\nservice: N & lectage: 2\n-0.0511\n0.0197\n-2.60\n0.0093\n\n\n\n\n\nservice: Y & lectage: 2\n-0.1139\n0.0233\n-4.89\n&lt;1e-05\n\n\n\n\n\nservice: N & lectage: 3\n-0.1065\n0.0211\n-5.06\n&lt;1e-06\n\n\n\n\n\nservice: Y & lectage: 3\n-0.1023\n0.0267\n-3.83\n0.0001\n\n\n\n\n\nservice: N & lectage: 4\n-0.1797\n0.0252\n-7.14\n&lt;1e-12\n\n\n\n\n\nservice: Y & lectage: 4\n-0.1939\n0.0294\n-6.61\n&lt;1e-10\n\n\n\n\n\nservice: N & lectage: 5\n-0.2079\n0.0283\n-7.34\n&lt;1e-12\n\n\n\n\n\nservice: Y & lectage: 5\n-0.1180\n0.0312\n-3.77\n0.0002\n\n\n\n\n\nservice: N & lectage: 6\n-0.2712\n0.0264\n-10.27\n&lt;1e-24\n\n\n\n\n\nservice: Y & lectage: 6\n-0.2268\n0.0293\n-7.74\n&lt;1e-14\n\n\n\n\n\nResidual\n1.1759\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit(MixedModel,\n          @formula(y ~ 1 + (studage + lectage + service)^2 +\n                      (1 | s) +\n                      (1 | d) +\n                      (1 | dept)),\n          insteval; progress)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_s\nσ_d\nσ_dept\n\n\n(Intercept)\n3.2285\n0.0368\n87.85\n&lt;1e-99\n0.3264\n0.5092\n0.0800\n\n\nstudage: 4\n0.1280\n0.0340\n3.77\n0.0002\n\n\n\n\n\nstudage: 6\n0.1525\n0.0343\n4.45\n&lt;1e-05\n\n\n\n\n\nstudage: 8\n0.2326\n0.0399\n5.83\n&lt;1e-08\n\n\n\n\n\nlectage: 2\n0.0554\n0.0302\n1.84\n0.0662\n\n\n\n\n\nlectage: 3\n-0.0273\n0.0640\n-0.43\n0.6702\n\n\n\n\n\nlectage: 4\n-0.1302\n0.0724\n-1.80\n0.0720\n\n\n\n\n\nlectage: 5\n-0.0885\n0.0807\n-1.10\n0.2728\n\n\n\n\n\nlectage: 6\n-0.1707\n0.0836\n-2.04\n0.0411\n\n\n\n\n\nservice: Y\n-0.0364\n0.0278\n-1.31\n0.1912\n\n\n\n\n\nstudage: 4 & lectage: 2\n-0.1117\n0.0400\n-2.80\n0.0052\n\n\n\n\n\nstudage: 6 & lectage: 2\n-0.1638\n0.0397\n-4.13\n&lt;1e-04\n\n\n\n\n\nstudage: 8 & lectage: 2\n-0.1683\n0.0469\n-3.59\n0.0003\n\n\n\n\n\nstudage: 4 & lectage: 3\n-0.1105\n0.0694\n-1.59\n0.1112\n\n\n\n\n\nstudage: 6 & lectage: 3\n-0.1295\n0.0688\n-1.88\n0.0599\n\n\n\n\n\nstudage: 8 & lectage: 3\n-0.0811\n0.0714\n-1.14\n0.2557\n\n\n\n\n\nstudage: 4 & lectage: 4\n0.0420\n0.0765\n0.55\n0.5833\n\n\n\n\n\nstudage: 6 & lectage: 4\n-0.1273\n0.0770\n-1.65\n0.0983\n\n\n\n\n\nstudage: 8 & lectage: 4\n-0.1095\n0.0797\n-1.37\n0.1694\n\n\n\n\n\nstudage: 4 & lectage: 5\n-0.1794\n0.0964\n-1.86\n0.0627\n\n\n\n\n\nstudage: 6 & lectage: 5\n-0.1400\n0.0831\n-1.68\n0.0921\n\n\n\n\n\nstudage: 8 & lectage: 5\n-0.1729\n0.0864\n-2.00\n0.0453\n\n\n\n\n\nstudage: 4 & lectage: 6\n0.0491\n0.0973\n0.50\n0.6137\n\n\n\n\n\nstudage: 6 & lectage: 6\n-0.0834\n0.0853\n-0.98\n0.3282\n\n\n\n\n\nstudage: 8 & lectage: 6\n-0.1821\n0.0867\n-2.10\n0.0358\n\n\n\n\n\nstudage: 4 & service: Y\n-0.0841\n0.0314\n-2.67\n0.0075\n\n\n\n\n\nstudage: 6 & service: Y\n-0.0068\n0.0333\n-0.21\n0.8376\n\n\n\n\n\nstudage: 8 & service: Y\n0.0157\n0.0364\n0.43\n0.6652\n\n\n\n\n\nlectage: 2 & service: Y\n-0.0841\n0.0301\n-2.79\n0.0053\n\n\n\n\n\nlectage: 3 & service: Y\n-0.0031\n0.0342\n-0.09\n0.9277\n\n\n\n\n\nlectage: 4 & service: Y\n-0.0350\n0.0379\n-0.93\n0.3547\n\n\n\n\n\nlectage: 5 & service: Y\n0.0651\n0.0416\n1.56\n0.1176\n\n\n\n\n\nlectage: 6 & service: Y\n0.0137\n0.0376\n0.37\n0.7150\n\n\n\n\n\nResidual\n1.1755\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoxCox.jl\nhttps://palday.github.io/BoxCox.jl/v0.3/\nBoxCox.jl implements a the Box-Cox transformation in an efficient way. Via package extensions, it supports specializations for MixedModels.jl and several plotting functions, but does not incur a dependency penalty for this functionality when MixedModels.jl or Makie.jl are not loaded.\n\nusing BoxCox\n\nbc = fit(BoxCoxTransformation, ss2)\n\nBox-Cox transformation\n\nestimated λ: -1.0747\nresultant transformation:\n\n y^-1.1 - 1\n------------\n    -1.1\n\n\n\nusing CairoMakie\nboxcoxplot(bc; conf_level=0.95)\n\n\n\n\n\n\n\n\nThe estimated λ is very close to -1, i.e. the reciprocal of reaction time, which has a natural interpretation as speed. In other words, the Box-Cox transformation suggests that we should consider modelling the sleepstudy data as speed (reaction per unit time) instead of reaction time:\n\nfit(MixedModel, @formula(1000 / reaction ~ 1 + days + (1 + days|subj)), sleepstudy)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n3.9658\n0.1056\n37.55\n&lt;1e-99\n0.4190\n\n\ndays\n-0.1110\n0.0151\n-7.37\n&lt;1e-12\n0.0566\n\n\nResidual\n0.2698\n\n\n\n\n\n\n\n\n\n\n(We multiply by 1000 to get the responses per second instead of the responses per millisecond.)\n\n\n\n\n\n\nTip\n\n\n\nBoxCox.jl also works with classical linear models.\n\n\n\n\nEffects.jl\nhttps://beacon-biosignals.github.io/Effects.jl/v1.2/\nEffects.jl provides a convenient method to compute effects, i.e. predictions and associated prediction intervals computed at points on a reference grid. For models with a nonlinear link function, Effects.jl will also compute appropriate errors on the response scale based on the difference method.\nFor MixedModels.jl, the predictions are computed based on the fixed effects only.\nThe functionality of Effects.jl was inspired by the effects and emmeans packages in R and the methods within are based on Fox (2003).\n\nusing Effects\n\n\ndesign = Dict(:age =&gt; -15:1:20,\n              :anych =&gt; [true, false])\n\neff_logit = effects(design, gm1; eff_col=\"use\", level=0.95)\n\n\n72×6 DataFrame47 rows omitted\n\n\n\nRow\nage\nanych\nuse\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n-15\ntrue\n-1.46959\n0.286489\n-2.0311\n-0.908083\n\n\n2\n-14\ntrue\n-1.28615\n0.257766\n-1.79136\n-0.780934\n\n\n3\n-13\ntrue\n-1.11395\n0.231079\n-1.56686\n-0.661045\n\n\n4\n-12\ntrue\n-0.953009\n0.206509\n-1.35776\n-0.548258\n\n\n5\n-11\ntrue\n-0.803317\n0.184156\n-1.16426\n-0.442378\n\n\n6\n-10\ntrue\n-0.664877\n0.164139\n-0.986583\n-0.343171\n\n\n7\n-9\ntrue\n-0.537689\n0.146592\n-0.825003\n-0.250374\n\n\n8\n-8\ntrue\n-0.421751\n0.131651\n-0.679783\n-0.16372\n\n\n9\n-7\ntrue\n-0.317066\n0.119429\n-0.551142\n-0.0829898\n\n\n10\n-6\ntrue\n-0.223631\n0.109967\n-0.439163\n-0.00810035\n\n\n11\n-5\ntrue\n-0.141449\n0.103187\n-0.343692\n0.0607949\n\n\n12\n-4\ntrue\n-0.0705172\n0.0988544\n-0.264268\n0.123234\n\n\n13\n-3\ntrue\n-0.0108372\n0.0965798\n-0.20013\n0.178456\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n61\n9\nfalse\n-1.98321\n0.392281\n-2.75207\n-1.21436\n\n\n62\n10\nfalse\n-2.13625\n0.417877\n-2.95527\n-1.31723\n\n\n63\n11\nfalse\n-2.30054\n0.444724\n-3.17218\n-1.4289\n\n\n64\n12\nfalse\n-2.47608\n0.472869\n-3.40288\n-1.54927\n\n\n65\n13\nfalse\n-2.66287\n0.502355\n-3.64747\n-1.67827\n\n\n66\n14\nfalse\n-2.86091\n0.533224\n-3.90601\n-1.81581\n\n\n67\n15\nfalse\n-3.07021\n0.565511\n-4.17859\n-1.96183\n\n\n68\n16\nfalse\n-3.29075\n0.59925\n-4.46526\n-2.11625\n\n\n69\n17\nfalse\n-3.52255\n0.63447\n-4.76609\n-2.27901\n\n\n70\n18\nfalse\n-3.7656\n0.671198\n-5.08112\n-2.45008\n\n\n71\n19\nfalse\n-4.0199\n0.709457\n-5.41041\n-2.62939\n\n\n72\n20\nfalse\n-4.28545\n0.749269\n-5.75399\n-2.81691\n\n\n\n\n\n\n\n\neff_prob = effects(design, gm1; eff_col=\"use\", level=0.95, invlink=AutoInvLink())\n\n\n72×6 DataFrame47 rows omitted\n\n\n\nRow\nage\nanych\nuse\nerr\nlower\nupper\n\n\n\nInt64\nBool\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n-15\ntrue\n0.187005\n0.0435561\n0.101636\n0.272373\n\n\n2\n-14\ntrue\n0.216506\n0.0437251\n0.130806\n0.302206\n\n\n3\n-13\ntrue\n0.247135\n0.0429944\n0.162867\n0.331402\n\n\n4\n-12\ntrue\n0.27828\n0.0414753\n0.19699\n0.35957\n\n\n5\n-11\ntrue\n0.309316\n0.039343\n0.232205\n0.386427\n\n\n6\n-10\ntrue\n0.339645\n0.0368141\n0.267491\n0.411799\n\n\n7\n-9\ntrue\n0.368725\n0.0341217\n0.301848\n0.435603\n\n\n8\n-8\ntrue\n0.396098\n0.0314915\n0.334375\n0.45782\n\n\n9\n-7\ntrue\n0.421391\n0.0291192\n0.364318\n0.478464\n\n\n10\n-6\ntrue\n0.444324\n0.0271508\n0.391109\n0.497539\n\n\n11\n-5\ntrue\n0.464697\n0.0256682\n0.414388\n0.515006\n\n\n12\n-4\ntrue\n0.482378\n0.0246829\n0.434\n0.530756\n\n\n13\n-3\ntrue\n0.497291\n0.0241442\n0.449969\n0.544613\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n61\n9\nfalse\n0.120977\n0.0417157\n0.0392156\n0.202738\n\n\n62\n10\nfalse\n0.105623\n0.0394755\n0.0282525\n0.182994\n\n\n63\n11\nfalse\n0.0910784\n0.0368156\n0.0189211\n0.163236\n\n\n64\n12\nfalse\n0.0775522\n0.033828\n0.0112505\n0.143854\n\n\n65\n13\nfalse\n0.0652002\n0.0306181\n0.00518977\n0.125211\n\n\n66\n14\nfalse\n0.0541199\n0.0272962\n0.000620278\n0.10762\n\n\n67\n15\nfalse\n0.044353\n0.0239696\n-0.00262663\n0.0913326\n\n\n68\n16\nfalse\n0.0358897\n0.020735\n-0.00475018\n0.0765296\n\n\n69\n17\nfalse\n0.0286773\n0.0176731\n-0.00596134\n0.063316\n\n\n70\n18\nfalse\n0.0226297\n0.0148453\n-0.00646652\n0.051726\n\n\n71\n19\nfalse\n0.0176381\n0.0122927\n-0.00645525\n0.0417314\n\n\n72\n20\nfalse\n0.0135804\n0.0100372\n-0.00609212\n0.033253\n\n\n\n\n\n\n\nEffects are particularly\n\nusing AlgebraOfGraphics # like ggplot2, but an algebra instead of a grammar\nusing CairoMakie\n\nplt1 = data(eff_logit) *\n      mapping(:age, :use; color=:anych) *\n      (visual(Lines) + mapping(; lower=:lower, upper=:upper) * visual(LinesFill))\ndraw(plt1)\n\n\n\n\n\n\n\n\n\nplt2 = data(eff_prob) *\n      mapping(:age, :use; color=:anych =&gt; \"children\") *\n      (visual(Lines) + mapping(; lower=:lower, upper=:upper) * visual(LinesFill))\ndraw(plt2)\n\n\n\n\n\n\n\n\n\nusing Statistics: mean\ncontra_by_age = transform(contra,\n                          :age =&gt; ByRow(x -&gt; round(Int, x)),\n                          :use =&gt; ByRow(==(\"Y\"));\n                          renamecols=false)\ncontra_by_age = combine(groupby(contra_by_age, [:age, :anych]),\n                        :use =&gt; mean =&gt; :use)\nplt3 = plt2 +\n       data(contra_by_age) *\n       mapping(:age, :use;\n               color=:anych =&gt; \"children\") * visual(Scatter)\n\ndraw(plt3;\n     axis=(; title=\"Estimated contraceptive use by age and children\",\n            limits=(nothing, (0, 1)) # ylim=0,1, xlim=auto\n            ))\n\n\n\n\n\n\n\n\nEffects and estimated marginal (least squares) means are closely related and partially concepts. Effects.jl provides convenience function emmeans and empairs for computing EM means and pairwise differences of EM means.\n\nemmeans(gm1)\n\n\n4×5 DataFrame\n\n\n\nRow\nage\nurban\nanych\nuse: Y\nerr\n\n\n\nFloat64\nString\nBool\nFloat64\nFloat64\n\n\n\n\n1\n0.00204757\nN\nfalse\n-1.3409\n0.221161\n\n\n2\n0.00204757\nY\nfalse\n-0.554174\n0.229898\n\n\n3\n0.00204757\nN\ntrue\n-0.127878\n0.112238\n\n\n4\n0.00204757\nY\ntrue\n0.658847\n0.149683\n\n\n\n\n\n\n\n\nempairs(gm1; dof=Inf)\n\n\n6×8 DataFrame\n\n\n\nRow\nage\nurban\nanych\nuse: Y\nerr\ndof\nt\nPr(&gt;|t|)\n\n\n\nFloat64\nString\nAny\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n0.00204757\nN &gt; Y\nfalse\n-0.786725\n0.319007\nInf\n-2.46617\n0.0136566\n\n\n2\n0.00204757\nN\nfalse &gt; true\n-1.21302\n0.248011\nInf\n-4.891\n1.00326e-6\n\n\n3\n0.00204757\nN &gt; Y\nfalse &gt; true\n-1.99975\n0.267053\nInf\n-7.4882\n6.98239e-14\n\n\n4\n0.00204757\nY &gt; N\nfalse &gt; true\n-0.426295\n0.255833\nInf\n-1.6663\n0.0956528\n\n\n5\n0.00204757\nY\nfalse &gt; true\n-1.21302\n0.274332\nInf\n-4.42172\n9.7919e-6\n\n\n6\n0.00204757\nN &gt; Y\ntrue\n-0.786725\n0.187089\nInf\n-4.20508\n2.60991e-5\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEffects.jl will work with any package that supports the StatsAPI.jl-based RegressionModel interface.\n\n\n\n\nStandardizedPredictors.jl\nhttps://beacon-biosignals.github.io/StandardizedPredictors.jl/v1/\nStandardizedPredictors.jl provides a convenient way to express centering, scaling, and z-standardization as a “contrast” via the pseudo-contrasts Center(), Scale, ZScore. Because these use the usual contrast machinery, they work well with any packages that use that machinery correctly (e.g. Effects.jl). The default behavior is to empirically compute the center and scale, but these can also be explicitly provided, either as a number or as a function (e.g. median to use the median for centering.)\n\nusing StandardizedPredictors\n\ncontrasts = Dict(:days =&gt; Center())\nfit(MixedModel,\n    @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy;\n    contrasts)\n\n\n\n\n\n\nEst.\nSE\nz\np\nσ_subj\n\n\n(Intercept)\n298.5079\n8.7950\n33.94\n&lt;1e-99\n36.4260\n\n\ndays(centered: 4.5)\n10.4673\n1.5022\n6.97\n&lt;1e-11\n5.7168\n\n\nResidual\n25.5919\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nStandardizedPredictors.jl will work with any package that supports the StatsModels.jl-based @formula and contrast machinery.\n\n\n\n\nRCall.jl and JellyMe4.jl\nhttps://juliainterop.github.io/RCall.jl/stable/\nhttps://github.com/palday/JellyMe4.jl/\nRCall.jl provides a convenient interface for interoperability with R from Julia. JellyMe4.jl extends the functionality of RCall so that MixedModels.jl-fitted models and lme4-fitted models can be translated to each other. In practical terms, this means that you can enjoy the speed of Julia for model fitting, but use all the extra packages you love from R’s larger ecosystem.\n\n\nReferences\n\n\nFox, J. (2003). Effect Displays in r for Generalised Linear Models. Journal of Statistical Software, 8(15). https://doi.org/10.18637/jss.v008.i15",
    "crumbs": [
      "Extension Packages"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mixed Effects Models in Julia",
    "section": "",
    "text": "This website contains the course materials for an introduction to mixed effects models in Julia using MixedModels.jl.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Mixed Effects Models in Julia",
    "section": "Prerequisites",
    "text": "Prerequisites\nThe material here assumes a basic proficiency with the Julia language, including a working Julia installation with Julia 1.9+.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#installation-of-course-materials",
    "href": "index.html#installation-of-course-materials",
    "title": "Mixed Effects Models in Julia",
    "section": "Installation of course materials",
    "text": "Installation of course materials\n\nJulia packages used in the examples\nThe source code for everything can be downloaded from GitHub. After downloading the materials, you should install the necessary Julia packages.\n\n\n\n\n\n\nTip\n\n\n\nWhen copying and pasting into the Julia REPL, you don’t need to remove the julia&gt; prompt from the examples. The Julia REPL will detect the prompt and strip it for you.\n\n\nFeel free to skip the movielens_download step – the relevant examples are provided only to show scaling with very large datasets.\n~/economics2024$ julia\n\njulia&gt; using Pkg\n\njulia&gt; Pkg.activate(\".\")\n  Activating project at `~/economics2024`\n\njulia&gt; Pkg.instantiate()\n&lt; lots of output &gt;\n\njulia&gt; using Econ2024\n\njulia&gt; Econ2024.movielens_download() # note: this is a very large dataset!\n[ Info: Downloading data\n[ Info: Extracting and saving ratings\n[ Info: Extracting movies that are in the ratings table\n[ Info: Extracting and saving README\n2-element Vector{String}:\n \"~/.julia/scratchspa\" ⋯ 28 bytes ⋯ \"3d4d5d689f47/data/ratings.arrow\"\n \"~/.julia/scratchspa\" ⋯ 27 bytes ⋯ \"-3d4d5d689f47/data/movies.arrow\"\n\njulia&gt; exit()\n\n\n\n\n\n\nImportant\n\n\n\nPlease check that you have the most recent version of the materials directly before the course.\n\n\n\n\nRendering the course website\nThis repository uses Quarto with the Julia code execution supplied by QuartoNotebookRunner.jl, which requires Quarto 1.5+.\nAs of early May 2024, Quarto 1.5 is only available as a preview release, which you’ll need to download from GitHub. Under each release’s “Assets”, you can find platform-specific installers.\n\n\n\n\n\n\nTip\n\n\n\nYou don’t need to install or use quarto to view the course materials. Everything, including the example code, is visible on the website, with links to the underlying source code for the entire page.\n\n\n~/economics2024$ quarto preview\n\n&lt; lots of output &gt;\n\nThis page was rendered from git revision befb445\n.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "02-plotting.html",
    "href": "02-plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "progress = false\n\nfalse\nIn the following, we’ll be using the Makie ecosystem for plottig. There are multiple major plotting ecosystems in Julia and it’s largely a matter of personal preference which to use. However, some plotting tools and packages only exist in one ecosystem, such as MixedModelsMakie.jl for several convenient plotting functions related to MixedModels.jl.\nusing CairoMakie # in Makie, you load a particular backend\nusing MixedModelsMakie\nMost plotting functions come in two variants: 1. “full-service” that generates a new plot for scratch 2. mutating, that modifies an existing plot or plots into a user-provided Figure or Axis (a component of a figure).\nFollowing the broader convention within Julia, the mutating variants include a ! in their name. It is quite common for the full service variant to be a minimal wrapper around the mutating variant and for the documentation of the full service variant to refer to the mutating variant, stating that all arguments are forwarded. We’ll see a few examples of this pattern in the following.",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#fixed-effects",
    "href": "02-plotting.html#fixed-effects",
    "title": "Plotting",
    "section": "Fixed Effects",
    "text": "Fixed Effects\nThe function coefplot creates a plot of the coefficient estimates along with associated confidence intervals.\n\ncoefplot(fm1)\n\n\n\n\n\n\n\n\nBecause the intercept is often on a different scale than categorical predictors and is not of particular interest, coefplot also not including it.\n\ncoefplot(fm1; show_intercept=false, color=:red)\n\n\n\n\n\n\n\n\nWe can use the mutating variant coefplot! to put the plots from all models into a single axis for comparison purposes.\n\nlet f = Figure()\n    ax = Axis(f[1, 1]; title=\"Comparison of estimates\")\n    coefplot!(ax, fm1; show_intercept=false, conf_level=0.68, label=\"fm1\")\n    coefplot!(ax, fm2; show_intercept=false, conf_level=0.68, label=\"fm2\")\n    coefplot!(ax, fm3; show_intercept=false, conf_level=0.68, label=\"fm3\")\n    axislegend(ax, \"model\"; merge=true, position=:rb) # _r_ight _b_ottom\n    f\nend",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#blups",
    "href": "02-plotting.html#blups",
    "title": "Plotting",
    "section": "BLUPs",
    "text": "BLUPs\nThe function caterpillar creates a similar plot of the BLUPs and their associated prediction intervals. The name caterpillar comes from the hairy appearance that occurs with large numbers of random effects. In lme4, the comparable plot was called dotplot.\n\n# select the grouping variable we want to plot\ncaterpillar(fm1, :dept)\n\n\n\n\n\n\n\n\nWhen plotting the BLUPs associated with a grouping variable with a very large number of levels, we can use qqcaterpillar, which combines a caterpillar plot a QQ-plot like spacing on the y-axis in order to give a better impression of the distribution of the random effects.\n\nqqcaterpillar(fm1, :dept)\n\n\n\n\n\n\n\n\n\nqqcaterpillar(fm1, :d)\n\n\n\n\n\n\n\n\nWhen a grouping variable is associated with multiple experimental variables, then each receives its own panel in the caterpillar plot.\n\ncaterpillar(fm2, :dept)\n\n\n\n\n\n\n\n\nBy default, the levels of the grouping variable are sorted by their value for the first column. However, we can select which variables are displayed and which column is used for sorting.\n\ncaterpillar(fm2, :dept; cols=[\"(Intercept)\", \"service: Y\"], orderby=2)\n\n\n\n\n\n\n\n\nBecause caterpillar plots can contain multiple axes, they cannot be plotted directly into an axis, but they can be plotted into a GridLayout (i.e. a sublayout) within a Figure.\n\nlet f = Figure(; title=\"Random effects\")\n    caterpillar!(f[1, 1], fm2, :dept)\n    Label(f[0, 1], \"dept\"; tellwidth=false)\n    qqcaterpillar!(f[1, 2], fm2, :d)\n    Label(f[0, 2], \"d(ozent)\"; tellwidth=false)\n    f\nend",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#qq-plots",
    "href": "02-plotting.html#qq-plots",
    "title": "Plotting",
    "section": "QQ Plots",
    "text": "QQ Plots\n\nqqnorm(fm1)\n\n\n\n\n\n\n\n\n\nqqplot(Normal(0, fm1.σ), fm1)",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "02-plotting.html#multiple-diagnostics",
    "href": "02-plotting.html#multiple-diagnostics",
    "title": "Plotting",
    "section": "Multiple diagnostics",
    "text": "Multiple diagnostics\n\nfunction diagnostic_plot!(f, model)\n    ax = Axis(f[1, 1]; xlabel=\"fitted\", ylabel=\"observed\",\n              title=\"Observed vs fitted\", aspect=AxisAspect(1))\n    scatter!(ax, fitted(model), response(model); alpha=0.5)\n    ablines!(ax, 0, 1; linestyle=:dash)\n\n    ax = Axis(f[1, 2]; xlabel=\"fitted\", ylabel=\"residual\",\n             title=\"Residuals vs fitted\")\n    scatter!(ax, fitted(model), residuals(model); alpha=0.5)\n    hlines!(ax, 0; linestyle=:dash)\n\n    ax = Axis(f[2, 1]; xlabel=\"theoretical quantiles\", ylabel=\"residuals\",\n             title=\"Normal QQ\", aspect=AxisAspect(1))\n    qqnorm!(ax, model)\n\n    ax = Axis(f[2, 2]; xlabel=\"Residual value\", ylabel=\"density\",\n             title=\"Residuals\")\n    density!(ax, residuals(model))\n\n    Label(f[0, :], \"Regression diagnostics\";\n          tellwidth=false, fontsize=24)\n\n    colsize!(f.layout, 1, Auto(0.5))\n\n    return f\nend\n\ndiagnostic_plot!(Figure(), sleep)",
    "crumbs": [
      "Visualization"
    ]
  },
  {
    "objectID": "04-bootstrap.html#shortest-coverage-highest-density-interval",
    "href": "04-bootstrap.html#shortest-coverage-highest-density-interval",
    "title": "The Parametric Bootstrap",
    "section": "Shortest coverage / highest density interval",
    "text": "Shortest coverage / highest density interval",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#equal-tail-probability-quantile-interval",
    "href": "04-bootstrap.html#equal-tail-probability-quantile-interval",
    "title": "The Parametric Bootstrap",
    "section": "Equal-tail probability / quantile interval",
    "text": "Equal-tail probability / quantile interval",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#distributed-computing",
    "href": "04-bootstrap.html#distributed-computing",
    "title": "The Parametric Bootstrap",
    "section": "Distributed computing",
    "text": "Distributed computing",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "04-bootstrap.html#lower-tolerances",
    "href": "04-bootstrap.html#lower-tolerances",
    "title": "The Parametric Bootstrap",
    "section": "Lower tolerances",
    "text": "Lower tolerances",
    "crumbs": [
      "Bootstrap"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html",
    "href": "99-wilkinson-notation.html",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "“Addition” (+) indicates additive, i.e., main effects: a + b indicates main effects of a and b.\n“Multiplication” (*) indicates crossing: main effects and interactions between two terms: a * b indicates main effects of a and b as well as their interaction.\nUsual algebraic rules apply (associativity and distributivity):\n\n(a + b) * c is equivalent to a * c + b * c\na * b * c corresponds to main effects of a, b, and c, as well as all three two-way interactions and the three-way interaction.\n\nCategorical terms are expanded into the associated indicators/contrast variables.\nTilde (~) is used to separate response from predictors.\nThe intercept is indicated by 1.\ny ~ 1 + (a + b) * c is read as:\n\nThe response variable is y.\nThe model contains an intercept.\nThe model contains main effects of a, b, and c.\nThe model contains interactions between a and c and between b and c but not a and b\n\nWe extend this notation for mixed-effects models with the grouping notation (|):\n\n(1 + a | subject) indicates “by-subject random effects for the intercept and main effect a”.\nThis is in line with the usual statistical reading of | as “conditional on”.\n\n\n\n\n\nModels fit with MixedModels.jl are generally linear mixed-effects models with unconstrained random effects covariance matrices and homoskedastic, normally distributed residuals. Under these assumptions, the model specification\nresponse ~ 1 + (age + sex) * education * n_children  + (1 | subject)\ncorresponds to the statistical model\n\\[\\begin{align*}\n\\left(Y |\\mathcal{B}=b\\right) &\\sim N\\left(X\\beta + Zb, \\sigma^2 I \\right) \\\\\n\\mathcal{B} &\\sim N\\left(0, G\\right)\n\\end{align*}\\]\nfor which we wish to obtain the maximum-likelihood estimates for \\(G\\) and thus the fixed-effects \\(\\beta\\).\n\nThe model contains no restrictions on \\(G\\), except that it is positive semidefinite.\nThe response Y is the value of a given response.\nThe fixed-effects design matrix X consists of columns for\n\nthe intercept, age, sex, education, and number of children (contrast coded as appropriate)\nthe interaction of all lower order terms, excluding interactions between age and sex\n\nThe random-effects design matrix Z includes a column for\n\nthe intercept for each subject",
    "crumbs": [
      "Formula Syntax"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html#general-rules",
    "href": "99-wilkinson-notation.html#general-rules",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "“Addition” (+) indicates additive, i.e., main effects: a + b indicates main effects of a and b.\n“Multiplication” (*) indicates crossing: main effects and interactions between two terms: a * b indicates main effects of a and b as well as their interaction.\nUsual algebraic rules apply (associativity and distributivity):\n\n(a + b) * c is equivalent to a * c + b * c\na * b * c corresponds to main effects of a, b, and c, as well as all three two-way interactions and the three-way interaction.\n\nCategorical terms are expanded into the associated indicators/contrast variables.\nTilde (~) is used to separate response from predictors.\nThe intercept is indicated by 1.\ny ~ 1 + (a + b) * c is read as:\n\nThe response variable is y.\nThe model contains an intercept.\nThe model contains main effects of a, b, and c.\nThe model contains interactions between a and c and between b and c but not a and b\n\nWe extend this notation for mixed-effects models with the grouping notation (|):\n\n(1 + a | subject) indicates “by-subject random effects for the intercept and main effect a”.\nThis is in line with the usual statistical reading of | as “conditional on”.",
    "crumbs": [
      "Formula Syntax"
    ]
  },
  {
    "objectID": "99-wilkinson-notation.html#mixed-models-in-wilkinson-rogers-and-mathematical-notation",
    "href": "99-wilkinson-notation.html#mixed-models-in-wilkinson-rogers-and-mathematical-notation",
    "title": "Wilkinson-Rogers (1973) notation for models of (co)variance",
    "section": "",
    "text": "Models fit with MixedModels.jl are generally linear mixed-effects models with unconstrained random effects covariance matrices and homoskedastic, normally distributed residuals. Under these assumptions, the model specification\nresponse ~ 1 + (age + sex) * education * n_children  + (1 | subject)\ncorresponds to the statistical model\n\\[\\begin{align*}\n\\left(Y |\\mathcal{B}=b\\right) &\\sim N\\left(X\\beta + Zb, \\sigma^2 I \\right) \\\\\n\\mathcal{B} &\\sim N\\left(0, G\\right)\n\\end{align*}\\]\nfor which we wish to obtain the maximum-likelihood estimates for \\(G\\) and thus the fixed-effects \\(\\beta\\).\n\nThe model contains no restrictions on \\(G\\), except that it is positive semidefinite.\nThe response Y is the value of a given response.\nThe fixed-effects design matrix X consists of columns for\n\nthe intercept, age, sex, education, and number of children (contrast coded as appropriate)\nthe interaction of all lower order terms, excluding interactions between age and sex\n\nThe random-effects design matrix Z includes a column for\n\nthe intercept for each subject",
    "crumbs": [
      "Formula Syntax"
    ]
  }
]